{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10.2: Tool Calling & Function Execution\n",
    "\n",
    "**Duration:** 40 minutes  \n",
    "**Level:** 3 (Advanced)  \n",
    "**Prerequisites:** M10.1 ReAct Pattern\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements production-grade tool calling for agentic RAG systems. You'll learn:\n",
    "\n",
    "- \u2705 Building a tool registry with 5+ production tools\n",
    "- \u2705 Implementing sandboxed execution (RestrictedPython)\n",
    "- \u2705 Timeout protection and retry logic\n",
    "- \u2705 Tool result validation\n",
    "- \u2705 Handling 5 common tool execution failures\n",
    "- \u2705 When NOT to use tool calling (critical trade-offs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial setup and imports\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import core module\n",
    "from l2_m10_tool_calling_function_execution import (\n",
    "    ToolRegistry,\n",
    "    ToolDefinition,\n",
    "    ToolCategory,\n",
    "    SafeToolExecutor,\n",
    "    ReActAgent,\n",
    "    register_default_tools,\n",
    "    tool_registry\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.WARNING)  # Keep output clean\n",
    "\n",
    "print(\"\u2705 Imports successful\")\n",
    "# Expected: No errors, confirmation message"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Section 1: Introduction & Problem Statement\n\n**The Challenge:**\n\nIn M10.1, you built a ReAct agent that can reason and act. But it can only *search* \u2014 not **DO** things.\n\nProduction agents need to:\n- Calculate risk scores\n- Query databases for policy documents\n- Call external APIs to check regulatory databases\n- Send Slack notifications when risks are detected\n- Generate charts showing compliance trends\n\n**The Problem:**\n\nGiving an LLM the ability to execute arbitrary code is dangerous:\n- \u274c Malformed tool calls crash your agent\n- \u274c Timeouts lock up your system indefinitely\n- \u274c Security holes execute malicious code\n- \u274c Invalid results corrupt agent state\n\n**Today's Solution:**\n\nBuild a robust tool ecosystem that's **powerful enough to be useful** but **safe enough for production**.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: Tool Calling Architecture (5-Step Process)\n\n**How Production Tool Calling Works:**\n\n**Step 1: Tool Definition**  \nDefine each tool with schema (what it does, parameters, return type). This becomes part of the LLM's system prompt.\n\n**Step 2: Tool Selection**  \nLLM decides which tool to use and outputs structured JSON: `{\"tool\": \"calculator\", \"args\": {\"expression\": \"0.25 * 1000000\"}}`\n\n**Step 3: Sandboxed Execution**  \nYour code parses JSON, validates arguments, executes tool in sandboxed environment with timeouts.\n\n**Step 4: Result Validation**  \nTool returns result. Before sending to LLM, validate it's expected type/format. Invalid results trigger retries.\n\n**Step 5: Observation Integration**  \nValidated result becomes next Observation in ReAct loop. Agent uses it to continue reasoning.\n\n**Why This Matters for Production:**\n- \ud83d\udee1\ufe0f **Safety:** Sandboxing prevents code injection attacks\n- \u23f1\ufe0f **Reliability:** Timeouts prevent hung tools from locking agent\n- \ud83d\udc1b **Debuggability:** Validation catches errors at tool boundary\n- \ud83d\udcca **Observability:** Every tool call is logged with inputs/outputs/timing",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Tool Registry Implementation\n\nThe Tool Registry is the central catalog of all available tools. It uses Pydantic for schema validation and provides:\n- Tool registration with validation\n- Tool discovery for LLM context\n- Execution statistics tracking",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Register default tools and inspect registry\nregister_default_tools(tool_registry)\n\n# List all registered tools\ntools = tool_registry.list_tools()\nprint(f\"Registered {len(tools)} tools:\\n\")\nfor tool in tools[:3]:  # Show first 3\n    print(f\"  \u2022 {tool.name} ({tool.category.value})\")\n    print(f\"    Timeout: {tool.timeout_seconds}s, Retries: {tool.retry_count}\")\n\n# Expected: 5 tools registered (search, calculator, database, api, slack)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 4: Sandboxed Execution Engine\n\nThe `SafeToolExecutor` provides three critical safety layers:\n\n1. **Argument Validation:** Checks arguments match tool schema before execution\n2. **Timeout Protection:** Uses ThreadPoolExecutor with configurable timeouts\n3. **Retry Logic:** Exponential backoff for transient failures (via tenacity library)\n\nThis prevents the 5 most common production failures.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize the safe executor\nexecutor = SafeToolExecutor(tool_registry)\n\n# Execute calculator tool safely\nresult = executor.execute_tool(\"calculator\", {\"expression\": \"2 + 2 * 10\"})\n\nprint(f\"Success: {result.success}\")\nprint(f\"Result: {result.result}\")\nprint(f\"Execution time: {result.execution_time_ms:.2f}ms\")\n\n# Expected: Success=True, Result={'result': 22, 'expression': '2 + 2 * 10'}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 5: Testing All 5 Production Tools\n\nLet's test each of the 5 registered tools to understand their behavior:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test all 5 tools\n",
    "print(\"1. Knowledge Search:\")\n",
    "r1 = executor.execute_tool(\"knowledge_search\", {\"query\": \"tool calling\", \"top_k\": 3})\n",
    "print(f\"   Found {r1.result['total_found']} results\" if r1.success else f\"   Error: {r1.error}\")\n",
    "\n",
    "print(\"\\n2. Calculator:\")\n",
    "r2 = executor.execute_tool(\"calculator\", {\"expression\": \"10000 * 0.002\"})\n",
    "print(f\"   Result: {r2.result['result']}\" if r2.success else f\"   Error: {r2.error}\")\n",
    "\n",
    "print(\"\\n3. Database Query:\")\n",
    "r3 = executor.execute_tool(\"database_query\", {\"query\": \"SELECT * FROM policies LIMIT 2\"})\n",
    "print(f\"   Rows: {r3.result['count']}\" if r3.success else f\"   Error: {r3.error}\")\n",
    "\n",
    "# Expected: All 3 tools execute successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Common Failures & Solutions (Critical Learning)\n",
    "\n",
    "These are the **5 most common production failures** and how our system handles them:\n",
    "\n",
    "### Failure 1: Code Injection Attack\n",
    "**Attack:** Malicious expression like `import os; os.system('rm -rf /')`  \n",
    "**Mitigation:** Calculator validates allowed characters only (0-9, +, -, *, /, (, ), space)\n",
    "\n",
    "### Failure 2: SQL Injection\n",
    "**Attack:** Query like `SELECT * FROM users; DROP TABLE users;`  \n",
    "**Mitigation:** Only SELECT queries allowed, parameterized statements\n",
    "\n",
    "### Failure 3: Tool Timeout\n",
    "**Scenario:** External API takes 60s to respond  \n",
    "**Mitigation:** Timeout enforced (default 30s), returns error instead of hanging\n",
    "\n",
    "### Failure 4: Invalid Arguments\n",
    "**Scenario:** LLM generates malformed JSON or missing required params  \n",
    "**Mitigation:** Schema validation rejects before execution\n",
    "\n",
    "### Failure 5: Non-serializable Result\n",
    "**Scenario:** Tool returns Python object instead of JSON  \n",
    "**Mitigation:** Result validation ensures JSON compatibility"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Demonstrate failure handling\n",
    "print(\"Testing Failure Scenarios:\\n\")\n",
    "\n",
    "# Failure 1: Code injection attempt\n",
    "r = executor.execute_tool(\"calculator\", {\"expression\": \"import os\"})\n",
    "print(f\"1. Code Injection: {'BLOCKED \u2705' if not r.success else 'FAILED \u274c'}\")\n",
    "print(f\"   Error: {r.error[:60]}...\\n\")\n",
    "\n",
    "# Failure 2: SQL injection attempt\n",
    "r = executor.execute_tool(\"database_query\", {\"query\": \"DROP TABLE users\"})\n",
    "print(f\"2. SQL Injection: {'BLOCKED \u2705' if not r.success else 'FAILED \u274c'}\")\n",
    "print(f\"   Error: {r.error}\\n\")\n",
    "\n",
    "# Failure 4: Invalid arguments\n",
    "r = executor.execute_tool(\"knowledge_search\", {})  # Missing required 'query'\n",
    "print(f\"3. Invalid Args: {'BLOCKED \u2705' if not r.success else 'FAILED \u274c'}\")\n",
    "\n",
    "# Expected: All attacks blocked, errors returned gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: ReAct Agent Integration\n",
    "\n",
    "Now let's integrate tool calling into a full ReAct agent loop.\n",
    "\n",
    "The agent follows the **Thought \u2192 Action \u2192 Observation** cycle:  \n",
    "1. **Thought:** LLM reasons about what to do next\n",
    "2. **Action:** Select tool + arguments (our executor runs it)\n",
    "3. **Observation:** Tool result feeds back into next iteration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run ReAct agent with tool calling\n",
    "agent = ReActAgent(executor)\n",
    "\n",
    "response = agent.run(\"How do I implement safe tool calling in production?\")\n",
    "\n",
    "print(f\"Success: {response['success']}\")\n",
    "print(f\"Iterations: {response['iterations']}\")\n",
    "print(f\"\\nAnswer: {response['answer'][:100]}...\")\n",
    "print(f\"\\nTrace steps: {len(response['trace'])}\")\n",
    "\n",
    "# Expected: Agent completes in 1-3 iterations with answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Trade-offs & When NOT to Use\n",
    "\n",
    "### Trade-offs Accepted:\n",
    "\n",
    "| Trade-off | Impact |\n",
    "|-----------|--------|\n",
    "| Sandboxing overhead | +50-200ms latency per tool |\n",
    "| Retry logic | May cause duplicate side effects |\n",
    "| Timeout interruption | Long operations get killed |\n",
    "| Restricted Python | Limited library access |\n",
    "\n",
    "### When NOT to Use Tool Calling:\n",
    "\n",
    "\u274c **Information-only agents** - If you only need search/retrieval, don't add tool complexity  \n",
    "\u274c **Sub-100ms latency requirements** - Sandboxing overhead is too high  \n",
    "\u274c **Non-idempotent tools** - Retry logic can cause duplicate operations  \n",
    "\u274c **Cascading failure dependencies** - When one tool failure breaks others\n",
    "\n",
    "### Alternative Solutions:\n",
    "\n",
    "**Pre-Approved Tool Outputs:** Static response database (zero execution risk, but inflexible)  \n",
    "**Human-in-the-Loop:** Require approval before execution (safer, but slower)  \n",
    "**Managed Platforms:** Zapier, n8n (vendor lock-in, but managed infrastructure)  \n",
    "**Container Isolation:** Docker/Podman (stronger isolation, higher resource cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Production Considerations\n",
    "\n",
    "### Cost Breakdown (10K conversations/hour):\n",
    "- **API calls:** $2,000-5,000/month (external services)\n",
    "- **Compute:** $500-1,000/month (if self-hosted)\n",
    "- **Storage:** $200-500/month (execution logs)\n",
    "\n",
    "### Monitoring Requirements:\n",
    "\u2705 Tool success/failure rates  \n",
    "\u2705 Execution latency percentiles (p50, p95, p99)  \n",
    "\u2705 Cost per tool call  \n",
    "\u2705 Error categorization and alerting\n",
    "\n",
    "### Deployment Checklist:\n",
    "1. Load test with realistic query patterns\n",
    "2. Implement circuit breakers for failing tools\n",
    "3. Set up distributed tracing for debugging\n",
    "4. Create runbooks for common failures\n",
    "5. Establish SLA targets for agent latency"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# View execution statistics\n",
    "print(\"Tool Execution Statistics:\\n\")\n",
    "stats = tool_registry.get_stats()\n",
    "\n",
    "for tool_name, tool_stats in stats.items():\n",
    "    if tool_stats['calls'] > 0:\n",
    "        success_rate = (tool_stats['successes'] / tool_stats['calls']) * 100\n",
    "        avg_time = tool_stats['total_time_ms'] / tool_stats['calls']\n",
    "        print(f\"{tool_name}:\")\n",
    "        print(f\"  Calls: {tool_stats['calls']}, Success Rate: {success_rate:.1f}%\")\n",
    "        print(f\"  Avg Time: {avg_time:.2f}ms\\n\")\n",
    "\n",
    "# Expected: Statistics for all executed tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Decision Card\n",
    "\n",
    "### Choose This Approach When:\n",
    "\u2705 Agents must take actions beyond retrieval  \n",
    "\u2705 You control tool implementations  \n",
    "\u2705 Latency targets permit 50-500ms overhead  \n",
    "\u2705 You can maintain retry-safe tool design\n",
    "\n",
    "### Avoid When:\n",
    "\u274c Tool failures cascade unpredictably  \n",
    "\u274c Sub-100ms latency is critical  \n",
    "\u274c External tools lack idempotency guarantees  \n",
    "\u274c You only need information retrieval\n",
    "\n",
    "### Next Steps:\n",
    "\u27a1\ufe0f **M10.3:** Multi-Agent Orchestration  \n",
    "\u27a1\ufe0f **M10.4:** Conversational RAG (multi-turn memory + tool calling)\n",
    "\n",
    "---\n",
    "\n",
    "## Practathon Challenges\n",
    "\n",
    "**Easy (90 min):** Add 2 custom tools (e.g., weather API, file reader)  \n",
    "**Medium (2-3 hrs):** Implement circuit breaker pattern for failing tools  \n",
    "**Hard (5-6 hrs):** Build tool versioning system + performance dashboard"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cleanup and summary\n",
    "executor.shutdown()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Module 10.2 Complete! \u2705\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nYou've learned:\")\n",
    "print(\"  \u2705 Tool registry with Pydantic validation\")\n",
    "print(\"  \u2705 Sandboxed execution with timeouts\")\n",
    "print(\"  \u2705 5 production tools (search, calc, DB, API, Slack)\")\n",
    "print(\"  \u2705 Handling 5 common failures\")\n",
    "print(\"  \u2705 When NOT to use tool calling (critical!)\")\n",
    "print(\"\\n\u26a0\ufe0f  Remember: Tool calling adds 50-500ms overhead\")\n",
    "print(\"\u26a0\ufe0f  Only use when agents need to DO things, not just search\")\n",
    "print(\"\\nNext: M10.4 - Conversational RAG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}