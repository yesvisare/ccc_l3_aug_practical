{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11.3: Resource Management & Throttling\n",
    "## Multi-Tenant SaaS Resource Allocation\n",
    "\n",
    "**Duration:** 38 minutes  \n",
    "**Level:** 3  \n",
    "**Prerequisites:** M11.1 (Tenant Isolation), M11.2 (Tenant Customization), Level 2 M6.3 (Rate Limiting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction & Hook\n",
    "\n",
    "### The Noisy Neighbor Problem\n",
    "\n",
    "You built tenant-specific customization in M11.2. That works great... until **Tenant A starts hammering your system with 10,000 queries per hour** while Tenant B can barely get a response.\n",
    "\n",
    "**Real-world impact:**\n",
    "- Response times: 2 seconds ‚Üí 30 seconds\n",
    "- OpenAI bill: $500/month ‚Üí $4,000/month\n",
    "- 49 other tenants suffering\n",
    "\n",
    "### What You'll Learn\n",
    "- Implement per-tenant rate limiting (100 queries/hour per tenant)\n",
    "- Build a fair query queue that prevents tenant starvation\n",
    "- Enforce resource quotas (query counts, API tokens, storage)\n",
    "- Handle emergency quota increases without redeploying\n",
    "- **Important:** When quotas are premature optimization (<50 tenants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úì Module 11.3: Resource Management & Throttling\")\n",
    "print(\"  Focus: Per-tenant quotas and fair scheduling\")\n",
    "\n",
    "# Expected:\n",
    "# ‚úì Module 11.3: Resource Management & Throttling\n",
    "#   Focus: Per-tenant quotas and fair scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: Prerequisites & Setup\n\n### Starting Point Verification\n\nYour Level 3 system currently has:\n- 50+ tenants with isolated namespaces (M11.1)\n- Per-tenant model customization (M11.2)\n- Global API rate limiting (Level 2 M6.3)\n- Redis for caching and distributed state\n\n**The gap:** Global rate limits don't prevent individual tenants from consuming disproportionate resources.\n\n### Dependencies Installation\n\nWe need Redis for quota tracking and queue management.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check dependencies and Redis connection\ntry:\n    import redis\n    from config import get_redis_client, Config\n    from l2_m11_resource_management_throttling import QuotaManager, FairTenantQueue\n    \n    print(\"‚úì Dependencies loaded\")\n    print(f\"  Redis config: {Config.REDIS_HOST}:{Config.REDIS_PORT}\")\n    \n    # Test Redis connection\n    try:\n        r = get_redis_client()\n        print(\"‚úì Redis connection successful\")\n        print(f\"  Version: {r.info('server').get('redis_version', 'unknown')}\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Skipping Redis calls (no connection): {e}\")\n        r = None\n        \nexcept ImportError as e:\n    print(f\"‚ö†Ô∏è Missing dependencies: {e}\")\n    print(\"  Run: pip install -r requirements.txt\")\n    r = None\n\n# Expected:\n# ‚úì Dependencies loaded\n# ‚úì Redis connection successful",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Theory Foundation\n\n### Core Concepts\n\nThink of your RAG system like an **apartment building** with 50 tenants sharing infrastructure:\n\n**Without management:** One tenant runs washing machine 24/7 ‚Üí no water pressure for others\n\n**With management:**\n1. **Individual metering** - Track each tenant's usage\n2. **Fair quotas** - Set reasonable limits per tenant\n3. **Queue discipline** - When demand exceeds capacity, serve fairly\n4. **Overflow handling** - What happens when tenants exceed quotas\n\n### Request Flow\n\n```\nRequest ‚Üí Tenant ID ‚Üí Quota Check\n                    ‚îú‚îÄ Under quota? ‚Üí Process immediately\n                    ‚îî‚îÄ Over quota? ‚Üí Queue or Reject\n\nQueue ‚Üí Round-robin scheduling ‚Üí Process when capacity available\n```\n\n### Why This Matters\n\n- **Prevents noisy neighbor** - Saves 20-40% infrastructure costs\n- **Predictable performance** - Maintains 2-3s p95 latency under load\n- **Cost control** - Prevents $10K+ surprise bills\n\n**Key insight:** Quotas are primarily for **system stability and fairness**, not just billing.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 4: Hands-On Implementation\n\n### Step 1: Per-Tenant Quota Tracker\n\nWe'll build a Redis-based system to track query counts, token usage, and storage per tenant with configurable limits.\n\n**Three quota tiers:**\n- **Free:** 100 queries/hour, 500K tokens/month\n- **Pro:** 1,000 queries/hour, 5M tokens/month\n- **Enterprise:** 10,000 queries/hour, 50M tokens/month",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from l2_m11_resource_management_throttling import QuotaManager, QuotaType\n\nif r:\n    # Initialize quota manager\n    qm = QuotaManager(r)\n    \n    # Set tenant to pro tier\n    qm.set_tenant_tier(\"tenant_demo\", \"pro\")\n    print(\"‚úì Set tenant_demo to pro tier\")\n    \n    # Record some queries\n    for i in range(3):\n        results = qm.record_query(\"tenant_demo\", tokens_used=1000)\n        print(f\"  Query {i+1}: hourly={results['queries_hourly']}, tokens ok={results.get('tokens_monthly', True)}\")\n    \n    # Check status\n    status = qm.get_quota_status(\"tenant_demo\")\n    hourly = status[\"quotas\"][\"queries_hourly\"]\n    print(f\"\\n‚úì Quota status: {hourly['current']}/{hourly['limit']} queries ({hourly['percentage']}%)\")\nelse:\n    print(\"‚ö†Ô∏è Skipping API calls (no Redis)\")\n\n# Expected:\n# ‚úì Set tenant_demo to pro tier\n# Query 1-3 recorded\n# ‚úì Quota status: 3/1000 queries (0.3%)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Step 2: Request Queue with Fair Scheduling\n\nNow we build a queue system that prevents tenant starvation using **round-robin scheduling**.\n\n**How it works:**\n- Each tenant has their own FIFO queue\n- We process one request from each tenant in turn\n- No tenant can monopolize resources",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from l2_m11_resource_management_throttling import FairTenantQueue, QueuedRequest\nimport asyncio\nimport time\n\nasync def demo_fair_queue():\n    if not r:\n        print(\"‚ö†Ô∏è Skipping API calls (no Redis)\")\n        return\n    \n    queue = FairTenantQueue(r, max_queue_size=10)\n    \n    # Enqueue requests from multiple tenants\n    tenants = [\"tenant_a\", \"tenant_b\", \"tenant_c\"]\n    for tenant in tenants:\n        for i in range(2):\n            req = QueuedRequest(\n                request_id=f\"{tenant}_req_{i}\",\n                tenant_id=tenant,\n                query=f\"Query {i} from {tenant}\",\n                queued_at=time.time()\n            )\n            await queue.enqueue(req)\n            print(f\"  Enqueued: {req.request_id}\")\n    \n    # Get stats\n    stats = queue.get_queue_stats()\n    print(f\"\\n‚úì Queue stats: {stats['total_queued_requests']} total, {stats['active_tenants']} tenants\")\n    \n    # Dequeue fairly (round-robin)\n    print(\"\\nDequeuing (round-robin order):\")\n    for _ in range(3):\n        req = await queue.dequeue_fair()\n        if req:\n            print(f\"  ‚Üí {req.tenant_id}: {req.request_id}\")\n\n# Run async function\nif r:\n    await demo_fair_queue()\nelse:\n    print(\"‚ö†Ô∏è Skipping API calls (no Redis)\")\n\n# Expected:\n# Enqueued 6 requests from 3 tenants\n# Dequeues alternate between tenants (fair)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 5: Reality Check\n\n### What This DOESN'T Do\n\n**1. Doesn't handle cross-service quotas**\n- Our quotas only track queries to this API\n- If tenants call OpenAI directly with their own keys, we can't track it\n\n**2. Doesn't optimize for cost**\n- We count queries, but not all queries cost the same\n- GPT-4 with 8K context costs 100x more than GPT-3.5 with 1K context\n- For true cost management, need weighted quotas\n\n**3. Doesn't prevent intentional abuse**\n- Malicious tenants can create multiple accounts\n- Need additional security (email verification, payment, abuse detection)\n\n### Trade-offs Accepted\n\n- **Complexity:** 600+ lines of quota management code\n- **Latency:** Quota checks add 5-15ms per request\n- **Operations:** Must monitor queue depth, Redis memory, handle quota requests\n\n### When This Breaks\n\n- **At 500+ tenants:** Redis memory grows to 2-5GB, need clustering\n- **At 10,000+ req/sec:** Quota checks bottleneck, need caching\n- **With SLA commitments:** Queue doesn't guarantee response time",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 6: Alternative Solutions\n\n### Alternative 1: No Quotas (Trust-Based)\n\n**Best for:** <50 tenants, all paying customers\n\n**Pros:** Zero complexity, best UX  \n**Cons:** One tenant can impact all others\n\n```python\n# Just log usage for monitoring\nawait usage_tracker.record(tenant_id, request.url.path)\n```\n\n### Alternative 2: Hard Limits (No Queuing)\n\n**Best for:** 50-200 tenants with clear tiers\n\n**Pros:** Simple (100 lines vs 600), predictable  \n**Cons:** Poor UX (hard rejections), no burst handling\n\n```python\nif tenant.usage_this_hour >= limit:\n    return JSONResponse(status_code=429, content={\"error\": \"Quota exceeded\"})\n```\n\n### Alternative 3: Dynamic Throttling\n\n**Best for:** 100+ tenants with variable usage\n\n**Pros:** Better resource utilization, adapts to traffic  \n**Cons:** Complex to tune, unpredictable for tenants\n\n### Alternative 4: Reserved Capacity (Enterprise)\n\n**Best for:** Enterprise customers paying $10K+/month\n\n**Pros:** Guaranteed performance, SLA-friendly  \n**Cons:** High cost, complex orchestration",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 7: When NOT to Use\n\n### Scenario 1: Small Tenant Count (<50 tenants)\n\n**Why it fails:** Complexity cost outweighs benefit\n\n**Use instead:** Alternative 1 (No Quotas) - just monitor and contact heavy users\n\n**Red flags:**\n- You spend more time managing quotas than building features\n- Team size <5 people\n\n### Scenario 2: Ultra-Low Latency Requirements (<50ms p95)\n\n**Why it fails:** Quota checks add 5-15ms; queuing adds 30-300s\n\n**Use instead:** Alternative 4 (Reserved Capacity) - dedicated resources\n\n**Red flags:**\n- Your SLA requires <50ms response time\n- Latency SLAs in contracts\n\n### Scenario 3: Highly Unpredictable Traffic (10x+ variance)\n\n**Why it fails:** Fair queuing assumes predictable load; 10x spikes fill queue instantly\n\n**Use instead:** Alternative 2 (Hard Limits) + aggressive auto-scaling\n\n**Red flags:**\n- Queue depth regularly >500 requests\n- Average wait time >60 seconds",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 8: Common Failures\n\n### Failure 1: Noisy Neighbor Exhausts Resources Despite Quotas\n\n**Root cause:** Quotas count queries, not resources. One GPT-4 query with 8K context costs 100x more than GPT-3.5 with 500 tokens.\n\n**The fix:** Use resource-weighted quotas",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from l2_m11_resource_management_throttling import ResourceWeightedQuota\n\nif r:\n    weighted = ResourceWeightedQuota(r)\n    \n    # Example: Different query costs\n    queries = [\n        {\"model\": \"gpt-3.5-turbo\", \"context\": \"small context\", \"use_tools\": False},\n        {\"model\": \"gpt-4\", \"context\": \"large \" * 1000, \"use_tools\": True},\n    ]\n    \n    print(\"Query weights (1.0 = standard query unit):\")\n    for i, q in enumerate(queries):\n        weight = weighted.calculate_query_weight(q)\n        print(f\"  Query {i+1} ({q['model']}): {weight:.1f}x\")\n    \n    print(\"\\n‚úì Weighted quotas prevent resource gaming\")\nelse:\n    print(\"‚ö†Ô∏è Skipping API calls (no Redis)\")\n\n# Expected:\n# Query 1 (gpt-3.5-turbo): 1.0x\n# Query 2 (gpt-4): 40-80x (expensive!)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Failure 2: Quota Enforcement Bypass via Race Conditions\n\n**Root cause:** Quota check and increment are not atomic. With concurrent requests, multiple read same value before increment.\n\n**The fix:** Use Redis Lua scripts for atomic check-and-increment",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from l2_m11_resource_management_throttling import AtomicQuotaManager\n\nif r:\n    atomic_qm = AtomicQuotaManager(r)\n    \n    # Set low limit for demo\n    atomic_qm.set_tenant_tier(\"tenant_atomic\", \"free\")\n    \n    # Atomic check-and-increment (prevents race conditions)\n    success1, current1, limit1 = atomic_qm.atomic_check_and_increment(\n        \"tenant_atomic\", QuotaType.QUERIES_HOURLY, increment=1\n    )\n    print(f\"Request 1: {'‚úì Allowed' if success1 else '‚úó Rejected'} ({current1}/{limit1})\")\n    \n    success2, current2, limit2 = atomic_qm.atomic_check_and_increment(\n        \"tenant_atomic\", QuotaType.QUERIES_HOURLY, increment=1\n    )\n    print(f\"Request 2: {'‚úì Allowed' if success2 else '‚úó Rejected'} ({current2}/{limit2})\")\n    \n    print(\"\\n‚úì Atomic operations prevent race condition bypass\")\nelse:\n    print(\"‚ö†Ô∏è Skipping API calls (no Redis)\")\n\n# Expected:\n# Both requests processed atomically, no bypass",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 9: Production Considerations\n\n### Scaling Concerns\n\n**Redis memory growth:**\n- 500 tenants √ó 5 time windows √ó 100 bytes = ~25MB for quotas\n- Add 100MB for queues = **125MB total**\n- Plan for 500MB with overhead\n\n**Quota check latency:**\n- Each request: 3 Redis operations (get, increment, check) = 3ms\n- At 1000 req/sec, Redis becomes bottleneck\n- Solution: Use Redis pipelining\n\n**Queue worker capacity:**\n- 5 workers √ó 2 req/sec = 10 req/sec = 600 req/min\n- If incoming rate exceeds this, queue grows\n- Monitor and auto-scale workers when depth >500\n\n### Cost at Scale (500 tenants)\n\n- **Redis:** $50-100/month (2GB managed)\n- **Queue workers:** $200-400/month (5 instances)\n- **Monitoring:** $50-100/month\n- **Engineering:** 8-12 hours/month\n\n**Total:** $300-600/month infrastructure + 1 week/month eng time",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 10: Decision Card\n\n### ‚úÖ BENEFIT\n- Prevents noisy neighbor problem\n- Maintains 2-3s p95 latency even under load\n- Caps infrastructure costs (~$500/month for 500 tenants)\n- Fair queue ensures all tenants served within 60s\n\n### ‚ùå LIMITATION\n- Adds 600+ lines of operational complexity\n- Cannot prevent resource gaming without weighted quotas\n- Requires human intervention for quota increases\n- Queue approach doesn't work for real-time (<5s) requirements\n\n### üí∞ COST\n- **Initial:** 12-16 hours implementation\n- **Ongoing:** $300-600/month + 8-12 hours/month management\n- **Complexity:** 3 new failure modes\n\n### ü§î USE WHEN\n- 50-500 tenants on shared infrastructure\n- Experiencing noisy neighbor complaints\n- Need predictable cost control\n- Can accept 10-20ms latency + 30-300s queue wait\n\n### üö´ AVOID WHEN\n- <50 tenants (use Alternative 1: No Quotas)\n- Need <50ms latency SLA (use Alternative 4: Reserved Capacity)\n- Highly spiky traffic (use Alternative 2: Hard Limits + auto-scale)\n- Team <5 people (wait or use managed service)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 11: Practice Exercises\n\n### üü¢ Easy: Basic Per-Tenant Rate Limiting (60-90 min)\n\nImplement simple per-tenant rate limiting without queuing:\n- Per-tenant quota tracking in Redis (queries per hour)\n- Three tier levels (free/pro/enterprise)\n- Middleware that rejects over-quota requests with 429\n- Admin endpoint to check tenant quota status\n\n### üü° Medium: Fair Queue Management (2-3 hours)\n\nAdd queue-based throttling with fair scheduling:\n- Build on Easy challenge\n- Implement FairTenantQueue with round-robin\n- Queue requests when tenant over quota\n- Background worker to process queued requests\n\n### üî¥ Hard: Production System (5-6 hours)\n\nBuild complete production system:\n- All Medium features\n- Weighted quotas (resource-aware)\n- Atomic quota checking (no race conditions)\n- Database-backed configuration\n- Bounded queue (global + per-tenant limits)\n- Comprehensive monitoring",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 12: Summary & Next Steps\n\n### What You Learned\n\n‚úì **Per-tenant quota tracking** with Redis (queries, tokens, storage)  \n‚úì **Fair queue scheduling** that prevents noisy neighbors  \n‚úì **Atomic quota checking** to avoid race conditions  \n‚úì **Weighted quotas** for resource-aware limits  \n‚úì **When quotas are premature** (<50 tenants) vs essential (>50 tenants)\n\n### Critical Takeaways\n\n1. **Quotas are for system stability** first, billing second\n2. **Fair scheduling is complex** - queue-depth awareness matters\n3. **Emergency quota increases** must not require deploys\n4. **Always use atomic operations** for quota checks (Lua scripts)\n5. **Bounded queues** prevent memory disasters during spikes\n\n### Real-World Application\n\nYou now have multi-tenant resource management for **50-500 tenants** that:\n- Prevents noisy neighbors\n- Gives sales team agility for quota adjustments\n- Works for 80% of SaaS applications\n\n### Next Steps\n\n1. Complete the practice challenge (choose your level)\n2. Implement monitoring (Prometheus metrics)\n3. Test under load (simulate 1000 req/sec)\n4. **Next module:** M11.4 Vector Index Sharding\n\n---\n\n**Great work! You're building real production systems now.**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}