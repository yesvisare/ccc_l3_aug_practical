{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Module 13: Enterprise RAG SaaS - Complete Multi-Tenant Integration\n\n## Learning Arc\n\n**Purpose:**  \nThis notebook demonstrates a production-ready, multi-tenant SaaS platform that integrates all previous L3 modules into a cohesive system. You'll build a Compliance Copilot that serves multiple paying customers with strict data isolation, flexible configuration, and accurate cost attribution.\n\n**Concepts Covered:**\n- Multi-tenant architecture patterns (namespace isolation, context propagation)\n- Configuration cascade (system \u2192 tenant \u2192 query overrides)\n- Resource attribution and billing (per-tenant usage tracking)\n- Production failure modes and mitigation strategies\n- Orchestration patterns for complex workflows\n\n**After Completing This Notebook:**\n- Understand when multi-tenancy overhead is justified (5-100 customers)\n- Implement tenant context propagation across async boundaries\n- Design configuration systems that balance flexibility and safety\n- Identify and fix common multi-tenant failure modes\n- Make informed trade-offs between simplicity and scale\n\n**Context in Track L3.M13:**  \nThis capstone module synthesizes everything: query decomposition (M9), multi-agent orchestration (M10), tenant isolation (M11), usage metering (M12), and complete SaaS integration (M13).",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Setup & Environment Check\n\nBefore running the code cells below, ensure you have:\n1. Installed dependencies: `pip install -r requirements.txt`\n2. (Optional) Configured API keys in `.env` for live API calls\n\n**Note:** This notebook runs in a simulated \"limited mode\" by default (no real API calls). All LLM and vector store operations are mocked for educational purposes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Environment setup and OFFLINE mode check\nimport os\nimport sys\nimport json\nimport asyncio\nfrom pathlib import Path\n\n# OFFLINE mode for L3 consistency (no real API calls)\nOFFLINE = os.getenv(\"OFFLINE\", \"true\").lower() == \"true\"\nif OFFLINE:\n    print(\"\u26a0\ufe0f  Running in OFFLINE mode \u2014 OpenAI/Pinecone calls will be skipped (mocked).\")\n    print(\"   To enable live API calls, set OFFLINE=false and configure .env with API keys.\\n\")\nelse:\n    print(\"\u2713 Running in LIVE mode with real API calls.\\n\")\n\n# Import from our module\nfrom src.l3_m13_complete_saas_build import (\n    ComplianceCopilotSaaS,\n    ConfigManager,\n    UsageTracker,\n    TenantContext,\n    ModelTier,\n    RetrievalMode\n)\n\nprint(\"\u2713 Imports successful\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Configuration Layer\n\nThe configuration cascade enables flexible settings management:\n- **System defaults**: Applied to all tenants\n- **Tenant defaults**: Override system settings per customer\n- **Query-level overrides**: Runtime adjustments without config changes\n\nThis pattern supports A/B testing, gradual rollouts, and customer-specific optimizations.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize configuration manager\nconfig_mgr = ConfigManager()\n\n# Set system defaults\nconfig_mgr.set_system_defaults(\n    model_tier=ModelTier.GPT35,\n    retrieval_mode=RetrievalMode.BASIC\n)\n\n# Load tenant configs (simulates database lookup)\nasync def demo_config():\n    config_acme = await config_mgr.load_tenant_config(\"acme_corp\")\n    config_beta = await config_mgr.load_tenant_config(\"beta_inc\")\n    \n    print(f\"ACME: {config_acme.model_tier.value}, namespace={config_acme.pinecone_namespace}\")\n    print(f\"BETA: {config_beta.model_tier.value}, namespace={config_beta.pinecone_namespace}\")\n    \n    # Override for premium tenant\n    config_mgr.update_tenant_config(\"acme_corp\", model_tier=ModelTier.GPT4)\n    updated = await config_mgr.load_tenant_config(\"acme_corp\")\n    print(f\"ACME upgraded: {updated.model_tier.value}\")\n\nawait demo_config()\n# Expected: 3 lines showing tenant configs and upgrade",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Tenant Context Propagation\n\nTenant identity must flow through all async operations to ensure:\n1. **Namespace isolation** in Pinecone (no cross-tenant data leakage)\n2. **Accurate billing attribution** for every API call\n3. **Distributed tracing** across service boundaries\n\nUses Python ContextVar for local async + OpenTelemetry baggage for distributed systems.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate context propagation\nasync def async_operation():\n    tenant = TenantContext.get_tenant()\n    print(f\"  \u2192 Async task sees tenant: {tenant}\")\n    return tenant\n\nasync def demo_context():\n    # Set tenant context\n    TenantContext.set_tenant(\"acme_corp\")\n    print(f\"Set context: {TenantContext.get_tenant()}\")\n    \n    # Context propagates through async calls\n    result = await async_operation()\n    \n    # Clean up\n    TenantContext.clear_tenant()\n    print(f\"After clear: {TenantContext.get_tenant()}\")\n\nawait demo_context()\n# Expected: 3 lines showing context propagation",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Orchestration Pattern\n\nThe `ComplianceCopilotSaaS` class coordinates the complete workflow:\n\n1. **Authentication verification** (not shown - assumes upstream API gateway)\n2. **Config loading** with cascade logic\n3. **Component initialization** (LLM, vector store)\n4. **Execution with context** (tenant ID propagated)\n5. **Post-processing** for metrics/billing\n\nThis centralization enables consistent error handling, logging, and observability.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize the orchestrator\ncopilot = ComplianceCopilotSaaS(\n    config_manager=config_mgr,\n    usage_tracker=UsageTracker()\n)\n\nprint(\"\u2713 ComplianceCopilotSaaS initialized\")\nprint(f\"  - Config manager: {type(copilot.config_manager).__name__}\")\nprint(f\"  - Usage tracker: {type(copilot.usage_tracker).__name__}\")\nprint(f\"  - Vector store: {type(copilot.vector_store).__name__}\")\n\n# Expected: 4 lines showing initialized components",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Document Ingestion with Namespace Isolation\n\nEach tenant's documents are stored in isolated Pinecone namespaces (`tenant_{id}`).\n\nThis ensures:\n- No cross-tenant data leakage\n- Independent document lifecycle management\n- Per-tenant storage limits enforcement",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load sample data\nwith open('example_data.json', 'r') as f:\n    data = json.load(f)\n\n# Ingest documents for each tenant\nasync def demo_ingestion():\n    for tenant_id, docs in data['sample_documents'].items():\n        result = await copilot.ingest_documents(\n            tenant_id=tenant_id,\n            documents=docs\n        )\n        print(f\"{tenant_id}: {result['documents_ingested']} docs \u2192 {result['namespace']}\")\n\nawait demo_ingestion()\n# Expected: 3 lines showing ingestion per tenant",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Multi-Tenant Query Execution\n\nEach query is executed with:\n1. Tenant context propagation (identity flows through all calls)\n2. Resource limit checks (quotas enforced per tenant)\n3. Namespace-isolated retrieval (only tenant's documents)\n4. Model tier selection (based on tenant config)\n5. Usage tracking for billing\n\nQuery-level overrides allow runtime customization without config changes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Execute queries from sample data\nasync def demo_queries():\n    for query_data in data['sample_queries'][:3]:  # First 3 queries\n        response = await copilot.query(\n            tenant_id=query_data['tenant_id'],\n            query_text=query_data['query']\n        )\n        \n        meta = response['metadata']\n        print(f\"{meta['tenant_id']}: {meta['latency_ms']:.1f}ms, \"\n              f\"model={meta['model']}, tokens={meta['tokens_used']}\")\n\nawait demo_queries()\n# Expected: 3 lines showing query results per tenant",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Usage Tracking & Billing Attribution\n\nEvery operation is tracked with:\n- Tenant ID (for attribution)\n- Operation type (query, ingestion, etc.)\n- Resource consumption (tokens, latency)\n- Success/failure status\n\n**Cost Breakdown Example (Monthly):**\n- Database: $50-200\n- Vector Store: $70-500\n- LLM APIs: $100-2000\n- Observability: $50-300\n\n**Common Failure:** Async billing lag - operations complete but billing delayed.  \n**Fix:** Background worker with retry queue.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# View tenant metrics and costs\nfor tenant_id in ['acme_corp', 'beta_inc', 'gamma_labs']:\n    metrics = copilot.get_tenant_metrics(tenant_id, hours=1)\n    costs = metrics['costs']\n    \n    print(f\"\\n{tenant_id}:\")\n    print(f\"  Queries: {metrics['successful_queries']}/{metrics['total_queries']}\")\n    print(f\"  Avg Latency: {metrics['avg_latency_ms']:.2f}ms\")\n    print(f\"  Tokens: {costs['total_tokens']}\")\n    print(f\"  Est. Cost: ${costs['estimated_llm_cost']:.4f}\")\n\n# Expected: Metrics for 3 tenants (~15 lines)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Common Failure Modes & Fixes\n\n### 1. Cache Race Conditions (Cross-Tenant Leakage)\n**Symptom:** Tenant A sees Tenant B's data  \\n**Cause:** Shared cache without tenant isolation  \\n**Fix:** Thread-safe caching with tenant-scoped locks\n\n### 2. Cascading Rate Limits\n**Symptom:** One heavy tenant blocks others  \\n**Fix:** Per-tenant rate limiting + circuit breakers\n\n### 3. Connection Pool Exhaustion\n**Symptom:** Timeouts during bulk operations  \\n**Fix:** Connection pooling + request batching\n\n### 4. OpenTelemetry Context Loss\n**Symptom:** Tracing breaks mid-chain  \\n**Fix:** Explicit context propagation in async boundaries\n\n### 5. Async Billing Lag\n**Symptom:** Usage tracked but billing delayed  \\n**Fix:** Background worker with retry queue",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate rate limiting (Failure Mode #2)\nasync def demo_rate_limit():\n    print(\"Testing rate limit protection...\")\n    \n    try:\n        # Our system allows 100 req/min per tenant\n        # Simulate rapid queries (will hit limit in real implementation)\n        for i in range(3):\n            response = await copilot.query(\n                tenant_id=\"test_tenant\",\n                query_text=f\"Query {i}\"\n            )\n            print(f\"  Query {i}: OK\")\n    \n    except Exception as e:\n        print(f\"  \u2713 Rate limit enforced: {str(e)}\")\n\nawait demo_rate_limit()\n# Expected: Either 3 OK responses or rate limit error",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Decision Card: When to Use This Architecture\n\n### \u2705 Use This When:\n- **5-100 paying customers** (sweet spot for multi-tenancy overhead)\n- **>500ms P95 latency acceptable** (allows for coordination overhead)\n- **Need strong tenant isolation** (data privacy requirements)\n- **Have DevOps expertise** (to manage infrastructure)\n- **Market size >100** (justifies engineering investment)\n\n### \u274c Avoid This When:\n- **<5 customers** \u2192 Overhead unjustified, start single-tenant\n- **<100 total market** \u2192 Overengineered for small opportunity\n- **<500ms latency required** \u2192 Coordination overhead too high\n- **No DevOps team** \u2192 Use managed platforms instead\n- **MVP stage** \u2192 Start simpler, add multi-tenancy later\n\n### \ud83d\udd04 Alternative Approaches:\n1. **MVP-first phasing**: Single-tenant \u2192 Add multi-tenancy incrementally\n2. **Microservices**: Separate services per component for independent scaling\n3. **Managed platforms**: Hosted RAG solutions for faster time-to-value\n4. **Tenant-per-instance**: Single-tenant SaaS copies for premium customers",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Production Deployment Checklist\n\n### Secrets Management\n- \u2713 All API keys in environment variables (never in code)\n- \u2713 Rotate secrets regularly (quarterly minimum)\n- \u2713 Use secret management service (AWS Secrets Manager, HashiCorp Vault)\n\n### Monitoring Dashboards\n- \u2713 Per-tenant query latency (P50/P95/P99)\n- \u2713 Error rates by tenant\n- \u2713 Token usage and cost attribution\n- \u2713 Rate limit violations\n\n### Alerting Thresholds\n- \u2713 P95 latency >1000ms\n- \u2713 Error rate >5%\n- \u2713 Any cross-tenant data leakage\n- \u2713 Database connection pool >80%\n\n### Incident Response\n- \u2713 On-call rotation documented\n- \u2713 Runbook for common failures\n- \u2713 Rollback procedure tested\n- \u2713 Customer communication templates\n\n### Load Testing (Practathon Challenge)\n- **Easy (10-15 hrs)**: 3 tenants, basic load testing\n- **Medium (15-20 hrs)**: Production-ready with comprehensive testing\n- **Hard (25-30 hrs)**: Multi-region deployment with failover\n\n**Target:** 1,000 req/hour across 100+ tenants, P95 < 500ms",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Final Summary\nprint(\"=\" * 60)\nprint(\"Module 13: Enterprise RAG SaaS - Complete\")\nprint(\"=\" * 60)\nprint(\"\\n\u2705 Demonstrated:\")\nprint(\"  1. Multi-tenant configuration cascade\")\nprint(\"  2. Context propagation across async boundaries\")\nprint(\"  3. Namespace isolation for data privacy\")\nprint(\"  4. Usage tracking & cost attribution\")\nprint(\"  5. Failure modes & mitigation strategies\")\nprint(\"\\n\ud83d\udcca Key Metrics:\")\nprint(f\"  - Tenants configured: {len([t for t in ['acme_corp', 'beta_inc', 'gamma_labs']])}\")\nprint(f\"  - Total queries executed: {sum(copilot.get_tenant_metrics(t, hours=1)['total_queries'] for t in ['acme_corp', 'beta_inc', 'gamma_labs'])}\")\nprint(f\"  - Avg P95 latency target: <500ms\")\nprint(\"\\n\ud83c\udfaf Next Steps:\")\nprint(\"  - Deploy FastAPI wrapper (app.py)\")\nprint(\"  - Add production monitoring\")\nprint(\"  - Run load tests (1000 req/hr target)\")\nprint(\"  - Configure multi-region failover (optional)\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}