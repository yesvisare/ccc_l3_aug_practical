{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# ðŸŽ“ Learning Arc: Module 12 - Usage Metering & Analytics\n\n## ðŸ“‹ Purpose\nLearn to build production-grade usage metering systems for multi-tenant SaaS applications. Bridge the gap between having a multi-tenant RAG API and being able to bill customers accurately or detect quota overages.\n\n## ðŸ”‘ Concepts Covered\n1. **Event-driven metering** - Capture usage events with tenant attribution\n2. **OLAP databases** - ClickHouse for 10-100x better aggregation performance\n3. **Materialized views** - Real-time pre-computed aggregations (hourly/daily)\n4. **Async buffering** - Non-blocking writes with <5ms overhead per request\n5. **Graceful degradation** - Fallback to local storage when database unavailable\n6. **Cost calculation** - Map usage quantities to billable amounts\n7. **Quota enforcement** - Prevent runaway costs with real-time overage detection\n8. **Billing export** - Generate monthly invoices from immutable event logs\n\n## âœ… After Completing This Module\nYou will be able to:\n- Design and implement a scalable usage metering pipeline\n- Choose between PostgreSQL and ClickHouse for time-series data\n- Build non-blocking event trackers that don't slow down APIs\n- Calculate costs from usage events with configurable pricing\n- Enforce tenant quotas and detect overages in real-time\n- Export billing data for invoice generation\n\n## ðŸ—ºï¸ Context in Track L3.M12\nThis module is part of **Level 3: SaaS Operations & Monetization**:\n- **Prerequisite**: L2.M7 (Observability) + L2.M11 (Multi-Tenant Architecture)\n- **Current Module**: M12.1 - Usage Metering & Analytics\n- **Next Module**: M12.2 - Advanced Analytics & Dashboarding with Grafana\n- **Related Modules**: M12.3 (Self-Service Tenant Onboarding), M12.4 (Tenant Lifecycle Management)\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12.1: Usage Metering & Analytics\n",
    "\n",
    "**Production-grade usage metering for multi-tenant SaaS applications**\n",
    "\n",
    "## Overview\n",
    "\n",
    "This module teaches building usage metering systems that bridge the gap between having a multi-tenant RAG API and being able to bill customers accurately or detect quota overages.\n",
    "\n",
    "**Key Architecture Components:**\n",
    "- Event capture at API endpoints with tenant attribution\n",
    "- Append-only storage in ClickHouse (columnar OLAP database)\n",
    "- Materialized views for real-time aggregations (hourly, daily)\n",
    "- Per-tenant dashboards and quota enforcement\n",
    "- Billing export for monthly invoice generation\n",
    "\n",
    "**Why ClickHouse over PostgreSQL:**\n",
    "- 10-100x better query performance on aggregations\n",
    "- Columnar storage optimized for time-series data\n",
    "- Handles 10,000+ events/day per tenant efficiently\n",
    "\n",
    "**Critical Design Decisions:**\n",
    "- Async architecture maintains <5ms overhead per request\n",
    "- Immutable event log provides complete audit trail\n",
    "- Fallback to local files if ClickHouse unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup and imports\nimport os\nimport sys\nimport json\nfrom datetime import datetime, timedelta\n\n# OFFLINE mode for L3 consistency\nOFFLINE = os.getenv(\"OFFLINE\", \"false\").lower() == \"true\"\nif OFFLINE:\n    print(\"âš ï¸ Running in OFFLINE mode â€” ClickHouse/DB calls will be skipped (mocked or use fallback).\")\n\n# Import our core module\nfrom src.l3_m12_usage_metering_analytics import (\n    UsageEvent, TenantQuota, ClickHouseSchema,\n    UsageTracker, CostCalculator, QuotaManager, BillingExporter\n)\nfrom config import get_clickhouse_client, get_config\n\n# Load sample data (from parent directory)\nwith open('../example_data.json') as f:\n    sample_data = json.load(f)\n\nprint(\"âœ“ Imports successful\")\nprint(f\"âœ“ Loaded {len(sample_data['sample_events'])} sample events\")\n\n# Expected:\n# âœ“ Imports successful\n# âœ“ Loaded 5 sample events"
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: ClickHouse Schema Setup\n\n**Four Primary Structures:**\n\n1. **`usage_events`** - Append-only event log\n   - Partitioned monthly for efficient queries\n   - Ordered by tenant_id + timestamp\n   - 36-month TTL for compliance\n\n2. **`usage_hourly`** - Materialized view\n   - Real-time hourly aggregations\n   - Tracks quantity and costs per event type\n\n3. **`usage_daily`** - Daily summaries\n   - Per-tenant daily totals\n   - Queries, tokens, storage metrics\n\n4. **`tenant_quotas`** - Quota tracking\n   - Limits and consumption per tenant",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize ClickHouse client (with graceful fallback)\nclient = get_clickhouse_client()\n\nif client:\n    # Initialize schema\n    success = ClickHouseSchema.initialize_schema(client)\n    print(f\"âœ“ Schema initialized: {success}\")\n    \n    # Show schema SQL\n    print(\"\\nðŸ“‹ Schema components:\")\n    for i, sql in enumerate(ClickHouseSchema.get_schema_sql(), 1):\n        table_name = sql.split(\"TABLE\")[1].split(\"(\")[0].strip().replace(\"IF NOT EXISTS\", \"\").strip()\n        print(f\"  {i}. {table_name}\")\nelse:\n    print(\"âš ï¸ Skipping schema init (ClickHouse not available)\")\n\n# Expected:\n# âš ï¸ Skipping schema init (ClickHouse not available)\n# OR\n# âœ“ Schema initialized: True\n# ðŸ“‹ Schema components: usage_events, usage_hourly, usage_daily, tenant_quotas",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Usage Tracker with Async Buffering\n\n**Design Goals:**\n- **Non-blocking writes** - Cannot slow down API responses\n- **<5ms overhead** per request\n- **Batch insertion** - 100 events or 1-second intervals\n- **Fallback storage** - Local JSONL files if ClickHouse unavailable\n\n**Key Feature: Graceful Degradation**\nIf the database is down, events are written to local files for later replay.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create sample events from example data\nimport asyncio\nimport uuid\n\n# Initialize tracker\ntracker = UsageTracker(client)\n\n# Create UsageEvent objects from sample data\nevents = []\nfor evt_data in sample_data['sample_events'][:3]:  # First 3 events\n    event = UsageEvent(\n        event_id=evt_data['event_id'],\n        tenant_id=evt_data['tenant_id'],\n        event_type=evt_data['event_type'],\n        quantity=evt_data['quantity'],\n        timestamp=datetime.fromisoformat(evt_data['timestamp'].replace('Z', '+00:00')),\n        metadata=evt_data['metadata']\n    )\n    events.append(event)\n    print(f\"ðŸ“ Event: {event.tenant_id} - {event.event_type} ({event.quantity})\")\n\nprint(f\"\\nâœ“ Created {len(events)} events\")\n\n# Expected:\n# ðŸ“ Event: tenant_acme - query (1)\n# ðŸ“ Event: tenant_acme - token_input (1500)\n# ðŸ“ Event: tenant_acme - token_output (800)\n# âœ“ Created 3 events",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 4: Cost Calculation Logic\n\n**Pricing Model:**\nMaps usage quantities to billable amounts based on configurable pricing:\n\n- **Queries**: $0.01 per query\n- **Input Tokens**: $0.003 per 1K tokens\n- **Output Tokens**: $0.015 per 1K tokens (5x input cost)\n- **Storage**: $0.10 per GB\n\n**Design:** Centralized pricing configuration allows easy updates without code changes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate costs for sample events\ncalculator = CostCalculator()\n\nprint(\"ðŸ’° Cost Calculation:\")\ntotal_cost = 0.0\nfor event in events:\n    cost = calculator.calculate_event_cost(event)\n    total_cost += cost\n    print(f\"  {event.event_type:15s} x {event.quantity:6.0f} = ${cost:.4f}\")\n\nprint(f\"\\nâœ“ Total cost: ${total_cost:.4f}\")\n\n# Verify against expected costs\nexpected = sample_data['expected_costs']\nprint(f\"âœ“ Expected: ${expected['evt_001'] + expected['evt_002'] + expected['evt_003']:.4f}\")\n\n# Expected:\n# ðŸ’° Cost Calculation:\n#   query           x      1 = $0.0100\n#   token_input     x   1500 = $0.0045\n#   token_output    x    800 = $0.0120\n# âœ“ Total cost: $0.0265",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 5: Quota Management & Overage Detection\n\n**Purpose:** Prevent runaway costs and enforce fair-use policies\n\n**Key Capabilities:**\n- Set per-tenant limits (queries/day, tokens/day, storage GB)\n- Real-time quota checking\n- Overage detection with configurable enforcement\n- Support for overage-allowed vs. hard-limit modes\n\n**Critical for:** Multi-tenant SaaS with freemium or tiered pricing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Set quota for sample tenant\nif client:\n    quota_mgr = QuotaManager(client)\n    \n    # Create quota from sample data\n    quota = TenantQuota(\n        tenant_id=\"tenant_acme\",\n        queries_per_day=1000,\n        tokens_per_day=100000,\n        storage_gb=10.0,\n        overage_allowed=True\n    )\n    \n    success = quota_mgr.set_quota(quota)\n    print(f\"âœ“ Quota set: {success}\")\n    \n    # Check quota status\n    status = quota_mgr.check_quota(\"tenant_acme\")\n    print(f\"\\nðŸ“Š Quota Status:\")\n    print(f\"  Status: {status.get('status', 'unknown')}\")\n    print(f\"  Remaining queries: {status.get('remaining', {}).get('queries', 'N/A')}\")\nelse:\n    print(\"âš ï¸ Skipping quota operations (ClickHouse not available)\")\n\n# Expected:\n# âš ï¸ Skipping quota operations (ClickHouse not available)\n# OR\n# âœ“ Quota set: True\n# ðŸ“Š Quota Status: within_quota",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 6: Billing Export & Invoice Generation\n\n**Monthly Invoice Data Structure:**\n- Period (year-month)\n- Line items with quantity, unit price, and amount\n- Total amount in USD\n- Detailed breakdown by event type\n\n**Integration:** Exports can feed into Stripe, QuickBooks, or custom billing systems.\n\n**Audit Trail:** Immutable event log ensures invoices can always be regenerated and verified.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generate monthly invoice\nif client:\n    exporter = BillingExporter(client)\n    \n    # Generate invoice for November 2025\n    invoice = exporter.export_monthly_invoice(\"tenant_acme\", 2025, 11)\n    \n    if 'error' not in invoice:\n        print(f\"ðŸ“„ Invoice: {invoice['period']}\")\n        print(f\"  Tenant: {invoice['tenant_id']}\")\n        print(f\"\\n  Line Items:\")\n        for item in invoice.get('line_items', [])[:3]:  # Show first 3\n            print(f\"    {item['description']:15s} {item['quantity']:6.0f} {item['unit']:10s} @ ${item['unit_price']:.4f} = ${item['amount']:.2f}\")\n        print(f\"\\n  ðŸ’µ Total: ${invoice['total_amount']:.2f}\")\n    else:\n        print(f\"âš ï¸ Invoice generation skipped: {invoice['error']}\")\nelse:\n    print(\"âš ï¸ Skipping invoice generation (ClickHouse not available)\")\n\n# Expected:\n# âš ï¸ Skipping invoice generation (ClickHouse not available)\n# OR\n# ðŸ“„ Invoice: 2025-11\n#   Line Items: [...list of charges...]\n#   ðŸ’µ Total: $X.XX",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 7: Common Failure Modes & Fixes\n\n### 1. Metering Data Loss\n**Risk:** Events not written if ClickHouse unavailable  \n**Solution:** Fallback to local file buffering with replay mechanism\n\n### 2. Aggregation Bugs\n**Risk:** Discrepancies between raw events and summaries  \n**Solution:** Regular reconciliation queries comparing totals\n\n### 3. Dashboard Performance\n**Risk:** Slow queries for large tenants with years of history  \n**Solution:** Monthly partitioning + pre-aggregated views (hourly/daily)\n\n### 4. Overage Detection Delays\n**Risk:** Tenants hit quotas without real-time notification  \n**Solution:** Sub-minute aggregation windows with alert rules\n\n### 5. Billing Reconciliation\n**Risk:** Invoiced amounts don't match usage records  \n**Solution:** Immutable event log enables auditing back to source",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate fallback behavior (Data Loss Mitigation)\nimport os\n\n# Tracker with no client will use fallback\nfallback_tracker = UsageTracker(client=None)\n\n# Create test event\ntest_event = UsageEvent(\n    event_id=\"test_001\",\n    tenant_id=\"tenant_test\",\n    event_type=\"query\",\n    quantity=1,\n    timestamp=datetime.now(),\n    metadata={\"test\": True}\n)\n\nprint(\"ðŸ”„ Testing fallback storage...\")\n# Note: In real async code, use await\n# For demo, we'll show the concept\nprint(f\"âœ“ Fallback file path: {fallback_tracker.client is None}\")\nprint(f\"âœ“ Event will write to: {os.path.basename(get_config()['fallback_file_path']) if 'fallback_file_path' in get_config() else 'usage_events_fallback.jsonl'}\")\n\n# Expected:\n# ðŸ”„ Testing fallback storage...\n# âœ“ Fallback file path: True\n# âœ“ Event will write to: usage_events_fallback.jsonl",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 8: Decision Card - When to Use This System\n\n### âœ… USE THIS APPROACH WHEN:\n\n1. **50+ customers** requiring billing transparency\n2. **Significant per-tenant usage variation** (10x+ differences)\n3. **Usage-based pricing** is core to business model\n4. **10,000+ events/day** across all tenants\n5. **Audit requirements** demand complete event history\n\n### âŒ DO NOT USE WHEN:\n\n1. **Early-Stage MVP (<50 customers)**\n   - Alternative: Manual tracking or simple database queries\n   - Reason: Infrastructure overhead unjustified\n\n2. **Low-Volume Internal Tools (<100 queries/day)**\n   - Alternative: Flat-rate or seat-based pricing\n   - Reason: Billing complexity premature\n\n3. **High-Frequency Trading (>10K requests/second)**\n   - Alternative: Specialized stream processing (Kafka + Flink)\n   - Reason: Event volume overwhelms typical metering\n\n### ðŸŽ¯ Quick Decision Test:\n**Use this system if:** 50+ tenants Ã— variable usage Ã— need billing transparency = YES\n\n### ðŸ’° Production Costs:\n- **Up to 50 tenants / 50K events/day:** Single ClickHouse instance (~$50/month)\n- **Estimated monthly cost:** $185 (ClickHouse) + operational overhead\n- **Engineering effort:** 4-8 hours implementation + ongoing monitoring",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Quick reference: Configuration summary\nconfig = get_config()\n\nprint(\"ðŸ“Š System Configuration Summary:\")\nprint(f\"\\n  ClickHouse: {config['clickhouse']['host']}:{config['clickhouse']['port']}\")\nprint(f\"  Database: {config['clickhouse']['database']}\")\nprint(f\"\\n  Buffering:\")\nprint(f\"    Buffer size: {config['buffering']['buffer_size']} events\")\nprint(f\"    Flush interval: {config['buffering']['flush_interval']}s (<5ms overhead)\")\nprint(f\"\\n  Pricing:\")\nfor key, value in config['pricing'].items():\n    print(f\"    {key}: ${value}\")\nprint(f\"\\n  Retention: {config['retention_months']} months (compliance)\")\n\n# Expected:\n# ðŸ“Š System Configuration Summary:\n#   ClickHouse: localhost:9000\n#   Buffer size: 100 events\n#   Flush interval: 1.0s (<5ms overhead)\n#   Pricing: {...}\n#   Retention: 36 months",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 9: Summary & Next Steps\n\n### âœ… What We Built:\n\n1. **ClickHouse Schema** - 4-table architecture with materialized views\n2. **Usage Tracker** - Async buffering with <5ms overhead\n3. **Cost Calculator** - Configurable pricing engine\n4. **Quota Manager** - Real-time overage detection\n5. **Billing Exporter** - Monthly invoice generation\n\n### ðŸ”‘ Key Takeaways:\n\n- **Performance:** 10-100x better than PostgreSQL for aggregations\n- **Reliability:** Fallback storage prevents data loss\n- **Auditability:** Immutable event log for compliance\n- **Scalability:** Handles 10,000+ events/day per tenant\n\n### ðŸ“ˆ Production Readiness:\n\n- **Metrics to Monitor:** Event write latency, buffer flush rate, aggregation lag\n- **Cost:** $185/month for 50 tenants\n- **Effort:** 4-8 hours implementation\n\n### ðŸš€ Next Module:\n\n**Module 12.2:** Advanced analytics and dashboarding with Grafana\n\n---\n\n**Practathon Challenges:**\n- **Easy (60-90 min):** Implement basic query metering\n- **Medium (2-3 hours):** Add token tracking + Grafana dashboard\n- **Hard (5-6 hours):** Full integration with overage alerts",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}