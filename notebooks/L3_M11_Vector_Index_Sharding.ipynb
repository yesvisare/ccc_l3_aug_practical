{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11.4: Vector Index Sharding for Multi-Tenant SaaS\n",
    "\n",
    "Production-grade sharding to overcome single-index limitations using consistent hashing.\n",
    "\n",
    "**Use sharding ONLY when:**\n",
    "- \\>80 tenants\n",
    "- \\>1M vectors total\n",
    "- Approaching 100 namespace limit\n",
    "- P95 latency \\>500ms\n",
    "\n",
    "**Trade-off:** Operational complexity vs scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nimport sys\nimport json\nfrom config import Config, get_clients\nfrom src.l3_m11_vector_index_sharding import ShardManager, ShardedRAG, monitor_shard_health\n\n# Initialize clients\npinecone_client, redis_client, openai_client = get_clients()\nprint(f\"✓ Services: Pinecone={pinecone_client is not None}, Redis={redis_client is not None}, OpenAI={openai_client is not None}\")\nprint(f\"✓ Configuration: {Config.NUM_SHARDS} shards, {Config.VECTOR_DIMENSION}D vectors\")\n\n# Expected:\n# ✓ Services: Pinecone=True/False, Redis=True/False, OpenAI=True/False\n# ✓ Configuration: 4 shards, 1536D vectors"
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Core Concept: Consistent Hashing\n\nTenants route deterministically to shards using **MurmurHash3**:\n\n```\nshard_id = abs(mmh3.hash(tenant_id)) % num_shards\n```\n\n**Why MurmurHash3?**\n- Fast (non-cryptographic)\n- Even distribution across shards\n- Deterministic: same input → same output\n\n**Redis backing:** Caches assignments to support controlled rebalancing without disrupting active queries.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate consistent hashing\nshard_manager = ShardManager(redis_client, num_shards=Config.NUM_SHARDS)\n\ntenants = [\"tenant-001\", \"tenant-002\", \"tenant-003\", \"tenant-004\", \"tenant-005\"]\nfor tenant_id in tenants:\n    shard_id = shard_manager.get_shard_for_tenant(tenant_id)\n    index_name = shard_manager.get_shard_index_name(tenant_id)\n    print(f\"{tenant_id} -> shard {shard_id} ({index_name})\")\n\n# Expected:\n# tenant-001 -> shard X (tenant-shard-X)\n# tenant-002 -> shard Y (tenant-shard-Y)\n# ... deterministic routing to 0-3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Ingesting Documents to Shards\n\nEach tenant's documents route to their assigned shard. Within the shard index, each tenant gets their own **namespace** (preserving isolation from M11.1-M11.3).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Load example data and ingest\nwith open('example_data.json', 'r') as f:\n    data = json.load(f)\n\nrag = ShardedRAG(pinecone_client, openai_client, shard_manager)\n\n# Ingest documents for first tenant\ntenant = data['tenants'][0]\nif pinecone_client and openai_client:\n    result = rag.upsert_documents(tenant['tenant_id'], tenant['documents'])\n    print(f\"Ingested {result.get('count', 0)} docs to {result.get('shard', 'N/A')}\")\nelse:\n    print(\"⚠️ Skipping ingestion (no API keys)\")\n\n# Expected:\n# Ingested 2 docs to tenant-shard-X\n# OR: ⚠️ Skipping ingestion (no API keys)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Single-Tenant Query (Fast Path)\n\n**Best practice:** Most queries should be single-tenant.\n\nHits only one shard, typical **P95 latency ~350ms**. This is the primary use case for production systems.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Single-tenant query example\nquery = data['queries'][0]  # tenant-001 query\ntenant_id = query['tenant_id']\nquery_text = query['query_text']\n\nif pinecone_client and openai_client:\n    result = rag.query_single_tenant(tenant_id, query_text, top_k=3)\n    print(f\"Query: '{query_text}'\")\n    print(f\"Shard: {result.get('shard', 'N/A')}, Latency: {result.get('latency_ms', 0):.0f}ms\")\n    print(f\"Results: {len(result.get('results', []))} matches\")\nelse:\n    print(\"⚠️ Skipping query (no API keys)\")\n\n# Expected:\n# Query: 'How does semantic search work?'\n# Shard: tenant-shard-X, Latency: ~350ms\n# Results: 0-3 matches",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Cross-Shard Query (Admin Use Only)\n\n**Use sparingly:** Cross-shard queries are slower and should be limited to admin/analytics operations.\n\nAggregates results from all shards. Higher latency due to multiple index queries + result merging.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cross-shard query (admin operation)\nadmin_query = data['queries'][2]  # No tenant_id - searches all shards\nquery_text = admin_query['query_text']\n\nif pinecone_client and openai_client:\n    result = rag.query_cross_shard(query_text, top_k=3)\n    print(f\"Cross-shard query: '{query_text}'\")\n    print(f\"Shards queried: {result.get('shards_queried', 0)}, Latency: {result.get('latency_ms', 0):.0f}ms\")\n    print(f\"Total results: {len(result.get('results', []))}\")\nelse:\n    print(\"⚠️ Skipping cross-shard query (no API keys)\")\n\n# Expected:\n# Cross-shard query: 'Best practices for monitoring'\n# Shards queried: 4, Latency: >800ms (slower than single-tenant)\n# Total results: 0-6 matches (aggregated)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Monitoring Shard Health\n\n**Production thresholds:**\n- Vector count: Rebalance at **300K/shard**\n- Namespace count: Alert at **18/20** capacity\n- P95 latency: Warn at **500ms**\n\nMonitor distribution to detect hot shards early.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check shard distribution\nstats = shard_manager.get_shard_stats()\nprint(\"Shard Distribution:\")\nfor shard_id, info in stats.items():\n    print(f\"  Shard {shard_id}: {info['tenant_count']} tenants\")\n\n# Monitor health (requires Pinecone connection)\nif pinecone_client:\n    health = monitor_shard_health(shard_manager, pinecone_client)\n    print(f\"\\nHealth: {'⚠️ Rebalancing needed' if health['needs_rebalancing'] else '✓ Healthy'}\")\n    if health['alerts']:\n        for alert in health['alerts']:\n            print(f\"  Alert: {alert}\")\nelse:\n    print(\"\\n⚠️ Skipping health check (no Pinecone)\")\n\n# Expected:\n# Shard Distribution:\n#   Shard 0: X tenants\n#   Shard 1: Y tenants...",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. When This Breaks: Hot Shard Problem\n\n**Symptom:** One shard accumulates large tenants, degrading performance.\n\n**Cause:** \n- Uneven tenant growth over time\n- Hash collision concentrates heavy users\n- No rebalancing strategy in place\n\n**Fix:** Explicit tenant reassignment for rebalancing.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Simulate hot shard detection and rebalancing\n# Assume shard 0 is overloaded, move a tenant to underutilized shard 3\n\nif redis_client:\n    # Check current assignment\n    tenant_to_move = \"tenant-001\"\n    old_shard = shard_manager.get_shard_for_tenant(tenant_to_move)\n    print(f\"Current: {tenant_to_move} on shard {old_shard}\")\n    \n    # Explicit reassignment (requires Redis)\n    target_shard = 3\n    shard_manager.assign_tenant_to_shard(tenant_to_move, target_shard)\n    \n    # Verify new assignment\n    new_shard = shard_manager.get_shard_for_tenant(tenant_to_move)\n    print(f\"After rebalancing: {tenant_to_move} on shard {new_shard}\")\nelse:\n    print(\"⚠️ Rebalancing requires Redis\")\n\n# Expected:\n# Current: tenant-001 on shard X\n# After rebalancing: tenant-001 on shard 3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Decision Card: When to Shard\n\n| Metric | Namespace Isolation | Sharded Architecture |\n|--------|-------------------|---------------------|\n| **Max Tenants** | ~100 | 1000s |\n| **Query Latency (P95)** | 200-400ms | Single: 350ms, Cross: 800ms+ |\n| **Operational Complexity** | Low | High |\n| **Cross-Tenant Queries** | Fast | Slow (avoid) |\n| **Rebalancing** | Not needed | Required skill |\n| **Cost** | 1 index fee | N × index fees |\n\n**Key Insight:** Start with namespace isolation (M11.1-M11.3). Only migrate to sharding when metrics prove necessity. Most SaaS apps never need sharding.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Decision helper function\ndef should_shard(num_tenants, total_vectors, p95_latency_ms, namespace_count):\n    \"\"\"Determine if sharding is justified.\"\"\"\n    reasons = []\n    \n    if num_tenants > 80:\n        reasons.append(f\"✓ {num_tenants} tenants (>80 threshold)\")\n    if total_vectors > 1_000_000:\n        reasons.append(f\"✓ {total_vectors:,} vectors (>1M threshold)\")\n    if namespace_count > 80:\n        reasons.append(f\"✓ {namespace_count} namespaces (approaching 100 limit)\")\n    if p95_latency_ms > 500:\n        reasons.append(f\"✓ {p95_latency_ms}ms P95 latency (>500ms threshold)\")\n    \n    return len(reasons) > 0, reasons\n\n# Test scenarios\nscenarios = [\n    (\"Small SaaS\", 30, 200_000, 250, 30),\n    (\"Growing SaaS\", 85, 1_200_000, 550, 75),\n]\n\nfor name, tenants, vectors, latency, namespaces in scenarios:\n    should, reasons = should_shard(tenants, vectors, latency, namespaces)\n    print(f\"{name}: {'SHARD' if should else 'Use namespaces'}\")\n    for r in reasons:\n        print(f\"  {r}\")\n\n# Expected:\n# Small SaaS: Use namespaces\n# Growing SaaS: SHARD (with reasons listed)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Common Failures & Fixes\n\n### Failure 1: Routing Inconsistency\n**Symptom:** Same tenant routes to different shards across requests.\n\n**Cause:** Redis connection lost, cache eviction, or inconsistent `num_shards` config.\n\n**Fix:** Verify Redis connectivity and consistent configuration.\n\n---\n\n### Failure 2: Cross-Shard Query Timeout\n**Symptom:** Admin queries timeout or return partial results.\n\n**Cause:** High latency aggregating results from multiple indexes.\n\n**Fix:** Lower `top_k` per shard, implement timeouts, or cache results.\n\n---\n\n### Failure 3: Rebalancing Disruption\n**Symptom:** Tenant queries fail during rebalancing.\n\n**Cause:** Moving data between shards without blue-green strategy.\n\n**Fix:** Use blue-green rebalancing:\n1. Write to both old and new shard\n2. Backfill data to new shard\n3. Switch reads to new shard\n4. Clean up old shard",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\n**What we covered:**\n1. ✓ Consistent hashing with MurmurHash3 for deterministic routing\n2. ✓ Single-tenant queries (fast path ~350ms)\n3. ✓ Cross-shard queries (slow, admin only)\n4. ✓ Shard health monitoring with production thresholds\n5. ✓ Hot shard problem detection and rebalancing\n6. ✓ Decision framework for when to shard\n\n**Key Trade-offs:**\n- Operational complexity → Scalability to 1000s of tenants\n- Single-tenant queries fast → Cross-shard queries slow\n- Higher cost (N × indexes) → Overcome single-index limits\n\n**Recommendation:** Start with namespace isolation. Migrate to sharding only when metrics justify the operational burden.\n\n**Next Steps:**\n- Configure `.env` with API keys\n- Run `pytest tests_smoke.py` to validate setup\n- Start API with `python app.py`\n- Monitor shard distribution and latency in production",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}