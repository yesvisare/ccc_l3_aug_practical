{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# L3.M11 \u2014 Vector Index Sharding for Multi-Tenant SaaS\n\n## Learning Arc\n\n**Purpose:** Master production-grade vector database sharding to scale beyond single-index limitations (100 namespaces, 1M+ vectors) using consistent hashing and Redis-backed routing.\n\n**Concepts Covered:**\n- Consistent hashing with MurmurHash3 for deterministic tenant routing\n- Single-tenant vs cross-shard query patterns and their latency trade-offs\n- Production monitoring thresholds (300K vectors/shard, 18/20 namespaces)\n- Hot shard detection and blue-green rebalancing strategies\n- Decision framework: when to shard vs when namespace isolation suffices\n\n**After Completing:**\nYou'll understand when sharding is justified (>80 tenants, >1M vectors, P95 >500ms) and how to implement it without sacrificing query performance. You'll recognize that most SaaS applications never need sharding\u2014namespace isolation from M11.1-M11.3 handles the majority of use cases.\n\n**Context in Track L3.M11:**\nThis module extends M11.1 (Tenant Isolation) and M11.2 (Tenant Metadata) by adding horizontal scaling when namespace-based isolation reaches platform limits. Critical for understanding enterprise SaaS architecture trade-offs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup\nimport sys\nimport json\nfrom config import Config, get_clients\nfrom src.l3_m11_vector_index_sharding import ShardManager, ShardedRAG, monitor_shard_health\n\n# Initialize clients\npinecone_client, redis_client, openai_client = get_clients()\nprint(f\"\u2713 Services: Pinecone={pinecone_client is not None}, Redis={redis_client is not None}, OpenAI={openai_client is not None}\")\nprint(f\"\u2713 Configuration: {Config.NUM_SHARDS} shards, {Config.VECTOR_DIMENSION}D vectors\")\n\n# Expected:\n# \u2713 Services: Pinecone=True/False, Redis=True/False, OpenAI=True/False\n# \u2713 Configuration: 4 shards, 1536D vectors"
  },
  {
   "cell_type": "markdown",
   "source": "# Setup\nimport sys\nimport json\nimport os\nfrom config import Config, get_clients\nfrom src.l3_m11_vector_index_sharding import ShardManager, ShardedRAG, monitor_shard_health\n\n# OFFLINE mode for L3 consistency\nOFFLINE = os.getenv(\"OFFLINE\", \"false\").lower() == \"true\"\nif OFFLINE:\n    print(\"\u26a0\ufe0f  Running in OFFLINE mode \u2014 API calls to /query or /ingest will be skipped (mocked).\")\n\n# Initialize clients\npinecone_client, redis_client, openai_client = get_clients()\nprint(f\"\u2713 Services: Pinecone={pinecone_client is not None}, Redis={redis_client is not None}, OpenAI={openai_client is not None}\")\nprint(f\"\u2713 Configuration: {Config.NUM_SHARDS} shards, {Config.VECTOR_DIMENSION}D vectors\")\n\n# Expected:\n# \u2713 Services: Pinecone=True/False, Redis=True/False, OpenAI=True/False\n# \u2713 Configuration: 4 shards, 1536D vectors",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate consistent hashing\nshard_manager = ShardManager(redis_client, num_shards=Config.NUM_SHARDS)\n\ntenants = [\"tenant-001\", \"tenant-002\", \"tenant-003\", \"tenant-004\", \"tenant-005\"]\nfor tenant_id in tenants:\n    shard_id = shard_manager.get_shard_for_tenant(tenant_id)\n    index_name = shard_manager.get_shard_index_name(tenant_id)\n    print(f\"{tenant_id} -> shard {shard_id} ({index_name})\")\n\n# Expected:\n# tenant-001 -> shard X (tenant-shard-X)\n# tenant-002 -> shard Y (tenant-shard-Y)\n# ... deterministic routing to 0-3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Ingesting Documents to Shards\n\nEach tenant's documents route to their assigned shard. Within the shard index, each tenant gets their own **namespace** (preserving isolation from M11.1-M11.3).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "## 2. Ingesting Documents to Shards\n\nEach tenant's documents route to their assigned shard using the ShardManager's consistent hash. Within the shard index, each tenant gets their own **namespace** (preserving isolation from M11.1-M11.3).\n\n**Architecture:** `tenant \u2192 hash \u2192 shard_id \u2192 index \u2192 namespace(tenant_id)`\n\nThis two-level isolation (shard + namespace) enables both horizontal scaling and tenant security.",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Single-Tenant Query (Fast Path)\n\n**Best practice:** Most queries should be single-tenant.\n\nHits only one shard, typical **P95 latency ~350ms**. This is the primary use case for production systems.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "## 3. Single-Tenant Query (Fast Path)\n\n**Best practice:** 99% of production queries should be single-tenant.\n\nHits only one shard using the deterministic routing. Typical **P95 latency ~350ms**\u2014comparable to non-sharded systems. The ShardManager routes the query to the correct index, then queries only that tenant's namespace.",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Cross-Shard Query (Admin Use Only)\n\n**Use sparingly:** Cross-shard queries are slower and should be limited to admin/analytics operations.\n\nAggregates results from all shards. Higher latency due to multiple index queries + result merging.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cross-shard query (admin operation)\nadmin_query = data['queries'][2]  # No tenant_id - searches all shards\nquery_text = admin_query['query_text']\n\nif pinecone_client and openai_client:\n    result = rag.query_cross_shard(query_text, top_k=3)\n    print(f\"Cross-shard query: '{query_text}'\")\n    print(f\"Shards queried: {result.get('shards_queried', 0)}, Latency: {result.get('latency_ms', 0):.0f}ms\")\n    print(f\"Total results: {len(result.get('results', []))}\")\nelse:\n    print(\"\u26a0\ufe0f Skipping cross-shard query (no API keys)\")\n\n# Expected:\n# Cross-shard query: 'Best practices for monitoring'\n# Shards queried: 4, Latency: >800ms (slower than single-tenant)\n# Total results: 0-6 matches (aggregated)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Monitoring Shard Health\n\n**Production thresholds:**\n- Vector count: Rebalance at **300K/shard**\n- Namespace count: Alert at **18/20** capacity\n- P95 latency: Warn at **500ms**\n\nMonitor distribution to detect hot shards early.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check shard distribution\nstats = shard_manager.get_shard_stats()\nprint(\"Shard Distribution:\")\nfor shard_id, info in stats.items():\n    print(f\"  Shard {shard_id}: {info['tenant_count']} tenants\")\n\n# Monitor health (requires Pinecone connection)\nif pinecone_client:\n    health = monitor_shard_health(shard_manager, pinecone_client)\n    print(f\"\\nHealth: {'\u26a0\ufe0f Rebalancing needed' if health['needs_rebalancing'] else '\u2713 Healthy'}\")\n    if health['alerts']:\n        for alert in health['alerts']:\n            print(f\"  Alert: {alert}\")\nelse:\n    print(\"\\n\u26a0\ufe0f Skipping health check (no Pinecone)\")\n\n# Expected:\n# Shard Distribution:\n#   Shard 0: X tenants\n#   Shard 1: Y tenants...",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. When This Breaks: Hot Shard Problem\n\n**Symptom:** One shard accumulates large tenants, degrading performance.\n\n**Cause:** \n- Uneven tenant growth over time\n- Hash collision concentrates heavy users\n- No rebalancing strategy in place\n\n**Fix:** Explicit tenant reassignment for rebalancing.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Simulate hot shard detection and rebalancing\n# Assume shard 0 is overloaded, move a tenant to underutilized shard 3\n\nif redis_client:\n    # Check current assignment\n    tenant_to_move = \"tenant-001\"\n    old_shard = shard_manager.get_shard_for_tenant(tenant_to_move)\n    print(f\"Current: {tenant_to_move} on shard {old_shard}\")\n    \n    # Explicit reassignment (requires Redis)\n    target_shard = 3\n    shard_manager.assign_tenant_to_shard(tenant_to_move, target_shard)\n    \n    # Verify new assignment\n    new_shard = shard_manager.get_shard_for_tenant(tenant_to_move)\n    print(f\"After rebalancing: {tenant_to_move} on shard {new_shard}\")\nelse:\n    print(\"\u26a0\ufe0f Rebalancing requires Redis\")\n\n# Expected:\n# Current: tenant-001 on shard X\n# After rebalancing: tenant-001 on shard 3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Decision Card: When to Shard\n\n| Metric | Namespace Isolation | Sharded Architecture |\n|--------|-------------------|---------------------|\n| **Max Tenants** | ~100 | 1000s |\n| **Query Latency (P95)** | 200-400ms | Single: 350ms, Cross: 800ms+ |\n| **Operational Complexity** | Low | High |\n| **Cross-Tenant Queries** | Fast | Slow (avoid) |\n| **Rebalancing** | Not needed | Required skill |\n| **Cost** | 1 index fee | N \u00d7 index fees |\n\n**Key Insight:** Start with namespace isolation (M11.1-M11.3). Only migrate to sharding when metrics prove necessity. Most SaaS apps never need sharding.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Decision helper function\ndef should_shard(num_tenants, total_vectors, p95_latency_ms, namespace_count):\n    \"\"\"Determine if sharding is justified.\"\"\"\n    reasons = []\n    \n    if num_tenants > 80:\n        reasons.append(f\"\u2713 {num_tenants} tenants (>80 threshold)\")\n    if total_vectors > 1_000_000:\n        reasons.append(f\"\u2713 {total_vectors:,} vectors (>1M threshold)\")\n    if namespace_count > 80:\n        reasons.append(f\"\u2713 {namespace_count} namespaces (approaching 100 limit)\")\n    if p95_latency_ms > 500:\n        reasons.append(f\"\u2713 {p95_latency_ms}ms P95 latency (>500ms threshold)\")\n    \n    return len(reasons) > 0, reasons\n\n# Test scenarios\nscenarios = [\n    (\"Small SaaS\", 30, 200_000, 250, 30),\n    (\"Growing SaaS\", 85, 1_200_000, 550, 75),\n]\n\nfor name, tenants, vectors, latency, namespaces in scenarios:\n    should, reasons = should_shard(tenants, vectors, latency, namespaces)\n    print(f\"{name}: {'SHARD' if should else 'Use namespaces'}\")\n    for r in reasons:\n        print(f\"  {r}\")\n\n# Expected:\n# Small SaaS: Use namespaces\n# Growing SaaS: SHARD (with reasons listed)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Common Failures & Fixes\n\n### Failure 1: Routing Inconsistency\n**Symptom:** Same tenant routes to different shards across requests.\n\n**Cause:** Redis connection lost, cache eviction, or inconsistent `num_shards` config.\n\n**Fix:** Verify Redis connectivity and consistent configuration.\n\n---\n\n### Failure 2: Cross-Shard Query Timeout\n**Symptom:** Admin queries timeout or return partial results.\n\n**Cause:** High latency aggregating results from multiple indexes.\n\n**Fix:** Lower `top_k` per shard, implement timeouts, or cache results.\n\n---\n\n### Failure 3: Rebalancing Disruption\n**Symptom:** Tenant queries fail during rebalancing.\n\n**Cause:** Moving data between shards without blue-green strategy.\n\n**Fix:** Use blue-green rebalancing:\n1. Write to both old and new shard\n2. Backfill data to new shard\n3. Switch reads to new shard\n4. Clean up old shard",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\n**What we covered:**\n1. \u2713 Consistent hashing with MurmurHash3 for deterministic routing\n2. \u2713 Single-tenant queries (fast path ~350ms)\n3. \u2713 Cross-shard queries (slow, admin only)\n4. \u2713 Shard health monitoring with production thresholds\n5. \u2713 Hot shard problem detection and rebalancing\n6. \u2713 Decision framework for when to shard\n\n**Key Trade-offs:**\n- Operational complexity \u2192 Scalability to 1000s of tenants\n- Single-tenant queries fast \u2192 Cross-shard queries slow\n- Higher cost (N \u00d7 indexes) \u2192 Overcome single-index limits\n\n**Recommendation:** Start with namespace isolation. Migrate to sharding only when metrics justify the operational burden.\n\n**Next Steps:**\n- Configure `.env` with API keys (copy from `.env.example`)\n- Run `PYTHONPATH=$PWD pytest -q` or `.\\scripts\\run_tests.ps1` to validate setup\n- Start API with `PYTHONPATH=$PWD uvicorn app:app --reload` or `.\\scripts\\run_api.ps1`\n- Monitor shard distribution and latency in production using `/metrics` endpoint",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}