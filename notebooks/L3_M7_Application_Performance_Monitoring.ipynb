{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7.2: Application Performance Monitoring\n",
    "\n",
    "**Duration:** 38 minutes  \n",
    "**Prerequisites:** Level 1 M2.3 (Prometheus/Grafana) + Level 2 M7.1 (OpenTelemetry Tracing)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Integrate Datadog APM with existing OpenTelemetry tracing (without double instrumentation)\n",
    "- Profile production code to find bottlenecks down to the function level (with <5% overhead)\n",
    "- Detect memory leaks and CPU hotspots in live systems (without crashing production)\n",
    "- Optimize database queries using APM query analysis\n",
    "- Understand when APM is overkill and what cheaper alternatives exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction & Hook\n",
    "\n",
    "### The Problem\n",
    "\n",
    "In M7.1, you built distributed tracing with OpenTelemetry. You can see that your P95 query latency is 3.2 seconds. You know **WHICH** requests are slow. But here's the problem: you don't know **WHY** they're slow.\n",
    "\n",
    "**Real-world scenario:**\n",
    "- Production RAG system P95 latency jumped from 1.5s to 4.8s overnight\n",
    "- Traces showed slowdown was in 'generate response' span\n",
    "- That span had 47 function calls inside it\n",
    "- **Without APM:** 6 hours of manual logging to find the bottleneck\n",
    "- **With APM:** 30 seconds to identify O(n¬≤) loop in embeddings.py line 247\n",
    "\n",
    "### The Gap We're Filling\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ Logs (WHAT happened)\n",
    "‚îú‚îÄ‚îÄ Metrics (HOW MUCH happened)\n",
    "‚îú‚îÄ‚îÄ Traces (WHERE in the pipeline) ‚Üê M7.1\n",
    "‚îî‚îÄ‚îÄ APM (WHY at code level) ‚Üê Today\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: Prerequisites & Setup\n\n### Starting Point Verification\n\nYour Level 2 M7.1 system currently has:\n- OpenTelemetry tracing showing request flows\n- Traces visible in Jaeger UI\n- Spans tagged with custom attributes\n- Trace sampling configured (10-20%)\n\n**The gap:** When Jaeger shows a slow span, you can't see what's happening inside at the code level.\n\n### Dependencies Installation\n\nWe'll install:\n- `ddtrace`: Datadog APM library (agentless approach)\n- `py-spy`: Low-overhead profiling tool\n- `memory-profiler`: Memory leak detection",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Verify dependencies installation\nimport sys\n\nprint(\"Checking dependencies...\")\n\n# Check ddtrace (optional - APM will be disabled if missing)\ntry:\n    import ddtrace\n    print(f\"‚úì ddtrace: {ddtrace.__version__}\")\nexcept ImportError:\n    print(\"‚ö†Ô∏è  ddtrace not available - APM features disabled\")\n\n# Check OpenTelemetry (M7.1 prerequisite)\ntry:\n    import opentelemetry\n    print(f\"‚úì OpenTelemetry: available\")\nexcept ImportError:\n    print(\"‚ö†Ô∏è  OpenTelemetry not available - install for M7.1 compatibility\")\n\n# Expected: ddtrace 2.x.x or higher, OpenTelemetry available",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Theory Foundation\n\n### APM vs Tracing\n\n**Analogy: Debugging a Traffic Jam**\n\n- **Metrics** (Prometheus): \"Highway has 1,000 cars/hour, average speed 20mph\"\n- **Tracing** (OpenTelemetry): \"Car #47 took 45 minutes from entrance to exit, passing through zones A ‚Üí B ‚Üí C\"\n- **APM**: \"Car #47 spent 30 of those 45 minutes stopped in zone B because the left lane was blocked by a stalled truck at mile marker 23.7\"\n\n### How APM Works\n\n```\nYour Python App\n‚îú‚îÄ‚îÄ OpenTelemetry (Traces)\n‚îÇ   ‚îî‚îÄ‚îÄ Span: \"process_query\" - 2.5s\n‚îÇ\n‚îî‚îÄ‚îÄ Datadog APM (Profiling)\n    ‚îî‚îÄ‚îÄ WITHIN that span:\n        ‚îú‚îÄ‚îÄ Function: embedding_model() - 200ms\n        ‚îú‚îÄ‚îÄ Function: chunk_filter() - 2.1s ‚ö†Ô∏è\n        ‚îÇ   ‚îî‚îÄ‚îÄ Line 187: nested loop - 1.8s ‚ö†Ô∏è‚ö†Ô∏è\n        ‚îî‚îÄ‚îÄ Function: format_response() - 200ms\n```\n\n**Process:**\n1. APM agent samples your Python process (default: 100 samples/second)\n2. Each sample captures the call stack (which functions are executing)\n3. Over time, you get a statistical profile: \"85% of time is in chunk_filter()\"\n4. APM correlates this with your OpenTelemetry traces\n\n### Key Distinction\n\n**APM COMPLEMENTS tracing, doesn't replace it:**\n- Tracing: Shows request flow between services (the 'what' and 'where')\n- APM: Shows code execution within a service (the 'why')",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import configuration\nfrom config import apm_config\n\n# Display APM configuration (without sensitive data)\nprint(\"=== APM Configuration ===\")\nprint(f\"Service: {apm_config.DD_SERVICE}\")\nprint(f\"Environment: {apm_config.DD_ENV}\")\nprint(f\"Profiling enabled: {apm_config.DD_PROFILING_ENABLED}\")\nprint(f\"Sample rate: {apm_config.DD_TRACE_SAMPLE_RATE * 100}%\")\nprint(f\"Profiling capture: {apm_config.DD_PROFILING_CAPTURE_PCT}%\")\nprint(f\"Max CPU overhead: {apm_config.DD_PROFILING_MAX_TIME_USAGE_PCT}%\")\nprint(f\"Configured: {apm_config.is_configured}\")\n\n# Expected: Configuration loaded with production-safe defaults",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 4: Hands-On Implementation\n\n### Step 1: Initialize APM Manager\n\nThe APM Manager handles:\n- Datadog tracer configuration\n- OpenTelemetry compatibility bridge\n- Continuous profiler startup/shutdown\n- Production safety limits (max 5% CPU overhead)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize APM Manager\nfrom src.l3_m7_application_performance_monitoring import apm_manager\n\nprint(\"Initializing APM...\")\nsuccess = apm_manager.initialize()\n\nif success:\n    print(\"‚úÖ APM initialized successfully\")\n    print(f\"   Service: {apm_config.DD_SERVICE}\")\n    print(f\"   Environment: {apm_config.DD_ENV}\")\nelse:\n    print(\"‚ö†Ô∏è  APM initialization skipped\")\n    print(\"   Reason: No DD_API_KEY configured or ddtrace not installed\")\n    print(\"   Pipeline will work without APM profiling\")\n\n# Expected: APM initializes if keys configured, otherwise gracefully skips",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Step 2: Profiled RAG Pipeline\n\nThe ProfiledRAGPipeline demonstrates:\n- Custom profiling with `@tracer.wrap()` decorators\n- Span tagging (user_id, query_length)\n- Exception tracking\n- O(n¬≤) bottleneck simulation for APM detection\n\n**What APM will show:**\n```\nSpan: rag.query - 2,547ms\n‚îú‚îÄ Span: rag.embed_query - 201ms\n‚îú‚îÄ Span: rag.search_vectordb - 304ms\n‚îú‚îÄ Span: rag.process_context - 1,893ms ‚ö†Ô∏è\n‚îÇ  ‚îî‚îÄ Profile: _remove_overlapping_chunks() - 1,750ms\n‚îÇ     ‚îî‚îÄ Line 503: nested loop hotspot\n‚îî‚îÄ Span: rag.generate_response - 503ms\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test Profiled RAG Pipeline\nfrom src.l3_m7_application_performance_monitoring import ProfiledRAGPipeline\nimport time\n\npipeline = ProfiledRAGPipeline()\n\n# Process a sample query\nquery = \"What are the compliance requirements for data retention?\"\nuser_id = \"notebook_user\"\n\nprint(f\"Processing query: {query[:50]}...\")\nstart = time.time()\nresult = pipeline.process_query(query, user_id)\nduration = time.time() - start\n\nprint(f\"\\n‚úÖ Query processed in {duration:.2f}s\")\nprint(f\"   Response: {result['response'][:80]}...\")\nprint(f\"   Context length: {result['context_length']} chars\")\nprint(f\"   Results: {result['num_results']}\")\n\n# Expected: Query processes successfully, APM captures function-level timing",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 5: Memory Profiling & Leak Detection\n\n### Why Memory Leaks Matter\n\nMemory leaks are silent killers in production:\n- Gradual memory growth over hours/days\n- Process eventually OOM killed\n- Difficult to debug without profiling\n\n### Detection Strategy\n\n1. **Baseline tracking**: Record memory at startup\n2. **Periodic sampling**: Check memory every N requests\n3. **Growth analysis**: Alert if growth >10MB/hour\n4. **Leak identification**: Use objgraph to find growing objects\n\n### Memory Profiling with tracemalloc\n\n- Python built-in module\n- Tracks memory allocations\n- Low overhead (<5%)\n- Shows peak memory and growth",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Memory Leak Detection\nfrom src.l3_m7_application_performance_monitoring import monitor_memory_leak\n\nprint(\"Running memory leak detection (5 iterations)...\")\nresults = monitor_memory_leak(iterations=5)\n\nprint(f\"\\n=== Memory Leak Detection Results ===\")\nprint(f\"Iterations: {results['iterations']}\")\nprint(f\"Final growth: {results['final_growth_mb']:.2f} MB\")\nprint(f\"Average growth per iteration: {results['average_growth_per_iteration_mb']:.2f} MB\")\nprint(f\"Leak detected: {results['leak_detected']}\")\n\nif results['leak_detected']:\n    print(\"\\n‚ö†Ô∏è  MEMORY LEAK DETECTED\")\n    print(\"   Investigation needed: Check for unbounded caches, circular references\")\nelse:\n    print(\"\\n‚úÖ No significant memory leak detected\")\n\n# Expected: Leak detection completes, shows memory growth patterns",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 6: Reality Check\n\n### What This DOESN'T Do\n\n1. **Replace code optimization**: APM shows you the problem, you still have to fix it\n2. **Eliminate load testing**: Profiling shows behavior under load, not capacity limits\n3. **Diagnose network issues**: Use distributed tracing (M7.1) for cross-service problems\n\n### Trade-offs You Accepted\n\n1. **Performance overhead**: 2-5% CPU even with conservative sampling (1% profiling, 10% traces)\n2. **Cost**: $51-100/month minimum, rising to $300+ at scale\n3. **Complexity**: 300+ lines of config code, requires profiling expertise\n4. **Data privacy**: Telemetry sent to Datadog (third-party service)\n\n### When This Approach Breaks\n\n**Scenario 1: APM Overhead Crushes Performance**\n- Production-safe config: 1% profiling, 10% sampling\n- If you increase to 10% profiling + 100% sampling ‚Üí 5-15% slowdown\n- **Solution**: Always use production-safe defaults, load test first\n\n**Scenario 2: Cost Explosion**\n- Expected: $51/month for small deployment\n- At 100K requests/hour: $300-500/month due to per-span fees ($5 per 1M spans)\n- **Solution**: Adaptive sampling (reduce rate at high traffic)\n\n**Scenario 3: Memory Leak Not Detected**\n- APM samples periodically, may miss slow retention leaks\n- Leaks that grow <1MB/hour are hard to detect\n- **Solution**: Long-term monitoring (hours/days), use objgraph for deep analysis",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 7: Alternative Solutions\n\n### Alternative 1: Open-Source APM (Grafana Tempo + Grafana)\n\n**Cost**: $0 (self-hosted) or $50/month (Grafana Cloud)\n\n**Pros:**\n- Full control over data\n- No vendor lock-in\n- Integrates with existing Grafana dashboards\n\n**Cons:**\n- Manual setup (2-3 days)\n- Less powerful profiling than Datadog\n- No automatic code-level flame graphs\n\n**When to use**: Budget <$100/month, need data sovereignty, already using Grafana\n\n---\n\n### Alternative 2: Cloud Provider APM\n\n**Options:**\n- AWS X-Ray: $5 per 1M requests\n- GCP Cloud Profiler: Free for GCP users\n- Azure Application Insights: Pay-per-use\n\n**Pros:**\n- Native cloud integration\n- Simpler if already on AWS/GCP/Azure\n- Often cheaper at low scale\n\n**Cons:**\n- Vendor lock-in\n- Limited cross-cloud visibility\n- Less powerful than Datadog\n\n**When to use**: Single cloud deployment, already invested in cloud ecosystem\n\n---\n\n### Alternative 3: Manual Profiling (py-spy)\n\n**Cost**: $0\n\n**Pros:**\n- Zero overhead when not profiling\n- On-demand profiling\n- Great for one-time investigations\n\n**Cons:**\n- Manual process\n- No continuous monitoring\n- No correlation with traces\n\n**When to use**: Low traffic, occasional debugging, tight budget\n\n**Example:**\n```bash\n# Profile a running Python process\npy-spy record -o profile.svg --pid 12345\n\n# Profile for 60 seconds\npy-spy record -d 60 -o profile.svg -- python app.py\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 8: When NOT to Use APM\n\n### Scenario 1: Low Traffic (<1,000 requests/day)\n\n**Why NOT to use APM:**\n- Insufficient data for meaningful profiling patterns\n- Sampling 10% of 1,000 requests = 100 traces (not enough)\n- APM costs ($51/month) exceed infrastructure costs\n\n**What to use instead:**\n- py-spy for one-time profiling\n- Manual logging during development\n- Wait until traffic grows >1K requests/hour\n\n---\n\n### Scenario 2: Pre-Optimization (No Known Performance Problem)\n\n**Why NOT to use APM:**\n- Premature optimization wastes time\n- No baseline to compare against\n- APM overhead without benefit\n\n**What to do instead:**\n- Wait until P95 latency crosses threshold (e.g., 3s)\n- Use basic metrics (Prometheus) to identify issues first\n- Add APM when you have specific bottleneck to investigate\n\n**Decision rule:** Only add APM when you have a known performance problem that basic metrics can't diagnose\n\n---\n\n### Scenario 3: Tight Budget (<$100/month total infrastructure)\n\n**Why NOT to use APM:**\n- APM minimum: $51/month\n- At $100 total budget, APM is 50%+ of costs\n- Open-source alternatives available\n\n**What to use instead:**\n- Grafana Tempo (self-hosted, $0)\n- py-spy (manual profiling, $0)\n- Cloud provider APM if already on AWS/GCP (often cheaper)\n\n---\n\n### Scenario 4: Highly Sensitive Data (Healthcare, Finance, Government)\n\n**Why NOT to use APM:**\n- Telemetry sent to third-party (Datadog)\n- May violate data sovereignty requirements\n- Compliance concerns (HIPAA, PCI-DSS)\n\n**What to use instead:**\n- Self-hosted APM (Grafana Tempo)\n- On-premise profiling tools\n- Cloud provider APM in same region/jurisdiction\n\n---\n\n### Summary: Use APM When You Have ALL of These\n\n```\n‚úì High traffic (>1K requests/hour)\n‚úì Known performance problems (P95 >3s)\n‚úì Adequate budget ($50-200/month)\n‚úì Data privacy clearance for third-party telemetry\n```\n\nIf missing ANY of the above, consider alternatives.\"",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 9: Common Failures\n\n### Failure 1: APM Overhead Crushing Performance (5-15% slowdown)\n\n**How it happens:**\n```python\n# ‚ùå WRONG - Too aggressive\nDD_PROFILING_CAPTURE_PCT = 10  # 10% profiling\nDD_TRACE_SAMPLE_RATE = 1.0      # 100% sampling\n```\n\n**Symptom:**\n- P95 latency increased from 800ms to 1.2s (50% slowdown)\n- CPU usage increased from 70% to 95%\n\n**The fix:**\n```python\n# ‚úÖ CORRECT - Production-safe\nDD_PROFILING_CAPTURE_PCT = 1   # 1% profiling\nDD_TRACE_SAMPLE_RATE = 0.1      # 10% sampling\nDD_PROFILING_MAX_TIME_USAGE_PCT = 5  # Safety limit\n```\n\n---\n\n### Failure 2: Profiling Crashes Application (OOM)\n\n**How it happens:**\n```python\n# ‚ùå WRONG - memory_profiler in production\nfrom memory_profiler import profile\n\n@profile  # Line-by-line tracking = huge overhead\ndef process_batch(docs):\n    # 10,000 docs √ó 2MB snapshot = 20GB memory\n```\n\n**The fix:**\n```python\n# ‚úÖ CORRECT - Use Datadog's sampling-based profiling\nDD_PROFILING_MEMORY_ENABLED = True\n# No decorator needed - automatic sampling\n```\n\n---\n\n### Failure 3: Memory Leak Detection Challenges\n\n**Why leaks are hard to detect:**\n- Slow retention leaks (<1MB/hour)\n- APM samples periodically, may miss gradual growth\n- Need long-term monitoring (hours/days)\n\n**Solution:**\n```python\n# Run long-term monitoring\nresults = monitor_memory_leak(iterations=100)\n\n# Use objgraph for deep analysis\nimport objgraph\nobjgraph.show_growth()  # Shows growing object types\n```\n\n---\n\n### Failure 4: Query Optimization Complexity\n\n**Challenge:**\n- EXPLAIN ANALYZE shows sequential scan\n- Adding index doesn't help\n- Query planner decisions are complex\n\n**Solution:**\n- Start simple, optimize incrementally\n- Test indexes in staging with production data volumes\n- Use APM as starting point, not final answer\n\n---\n\n### Failure 5: APM Cost Explosion ($500+ bill)\n\n**How it happens:**\n- Expected: $51/month\n- Actual: $523/month\n- Cause: High traffic + 100% sampling = 100M spans/month\n\n**The fix:**\n```python\n# Adaptive sampling based on traffic\nif requests_per_hour > 10000:\n    DD_TRACE_SAMPLE_RATE = 0.01  # 1% for high traffic\nelse:\n    DD_TRACE_SAMPLE_RATE = 0.1   # 10% for normal traffic\n\n# Monitor span count in Datadog billing dashboard\n# Set budget alerts at $100, $200 thresholds\n```\"",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 10: Decision Card\n\n### ‚úÖ BENEFIT\n\nDeep code-level profiling reveals bottlenecks down to specific function calls and line numbers. Reduces debugging time from hours to minutes by showing CPU hotspots, memory leaks, and slow queries with flame graphs. Correlates performance issues with traces from M7.1.\n\n---\n\n### ‚ùå LIMITATION\n\nAdds 2-5% CPU overhead in production even with conservative sampling (1% profiling, 10% trace sampling). Cost scales rapidly: $51/month minimum, rising to $300+/month at 100K requests/hour due to per-span analysis fees ($5 per 1M spans). Memory profiling shows allocations but struggles to detect slow retention-based leaks.\n\n---\n\n### üí∞ COST\n\n- **Time to implement**: 2-4 hours for initial setup, 1-2 days for production tuning\n- **Monthly cost**: $51-100 for small deployments (1-3 hosts), $300-800 for medium scale (10-15 hosts, 10M spans/day)\n- **Complexity**: 300+ lines of APM config code, requires understanding of profiling overhead vs visibility trade-offs\n\n---\n\n### ü§î USE WHEN\n\n- Traffic exceeds 1K requests/hour with known performance problems (P95 >3s)\n- Budget allows $50-200/month for APM\n- Team of 3+ engineers who will actively monitor dashboards\n- No compliance restrictions on sending telemetry to third-party services (Datadog)\n\n---\n\n### üö´ AVOID WHEN\n\n- Traffic below 1K requests/hour (insufficient data for profiling patterns - use py-spy instead)\n- Budget under $100/month total (APM would be 50%+ of costs - use open-source Grafana Tempo)\n- Processing sensitive data requiring full data sovereignty (use self-hosted APM)\n- No known performance issues yet (premature optimization - wait until P95 crosses 3s)\n\n---\n\n### Decision Framework\n\n```\nChoose APM when you have ALL of:\n‚úì High traffic (>1K requests/hour)\n‚úì Known performance problems\n‚úì Adequate budget ($50-200/month)\n‚úì Data privacy clearance\n```\n\n**Save this card** - you'll reference it when deciding between Datadog APM, open-source alternatives, or manual profiling approaches.\"",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 11: Summary & Next Steps\n\n### What You Built Today\n\n- Full Datadog APM integration with OpenTelemetry bridge (connecting your M7.1 tracing)\n- Continuous profiling setup profiling 1% of requests with <5% CPU overhead\n- Memory leak detection system using tracemalloc\n- Production-safe configuration with cost controls\n\n### What You Learned\n\n‚úÖ How APM complements tracing by showing function-level bottlenecks (not just span-level)  \n‚úÖ Safe production profiling configuration (1% capture, 10% sampling, 5% max CPU)  \n‚úÖ Memory leak detection patterns and tools  \n‚úÖ When APM is overkill (low traffic, tight budgets, no known problems)  \n‚úÖ Cost management strategies (adaptive sampling, span filtering)\n\n### Key Takeaways\n\n1. **APM is not a replacement for optimization** - it shows you the problem, you fix it\n2. **Start conservative** - 1% profiling, 10% sampling, increase only if safe\n3. **Monitor costs** - APM can get expensive at scale ($300+/month)\n4. **Know when NOT to use it** - low traffic, tight budgets, premature optimization\n\n### Production Checklist\n\nBefore deploying APM to production:\n\n- [ ] API keys configured in `.env`\n- [ ] Sampling rates production-safe (‚â§10% traces, ‚â§1% profiling)\n- [ ] Safety limits set (`DD_PROFILING_MAX_TIME_USAGE_PCT=5`)\n- [ ] Load tested with APM enabled\n- [ ] APM overhead measured (<5% CPU increase)\n- [ ] Cost monitoring dashboard created\n- [ ] Budget alerts configured ($100, $200 thresholds)\n- [ ] Rollback plan documented\n\n### Next Steps\n\n1. **Explore Datadog UI**: If configured, visit https://app.datadoghq.com/apm/traces\n2. **Run load tests**: Generate traffic and observe APM profiling in real-time\n3. **Optimize bottlenecks**: Use APM to find and fix slow code paths\n4. **Next module**: Module 7.3 - Error Tracking & Root Cause Analysis\n\n---\n\n**Congratulations!** You've mastered Application Performance Monitoring for RAG systems.\"",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Final Demo: Complete APM Workflow\nprint(\"=\" * 60)\nprint(\"Module 7.2: Application Performance Monitoring - Complete Demo\")\nprint(\"=\" * 60)\nprint()\n\n# 1. Check APM status\nprint(\"1. APM Status:\")\nprint(f\"   Initialized: {apm_manager.is_initialized}\")\nprint(f\"   Configured: {apm_config.is_configured}\")\nprint()\n\n# 2. Run sample query\nprint(\"2. Processing sample query...\")\nquery = \"What are the compliance requirements?\"\nresult = pipeline.process_query(query, \"demo_user\")\nprint(f\"   ‚úÖ Query processed successfully\")\nprint()\n\n# 3. Check memory\nfrom src.l3_m7_application_performance_monitoring import MemoryProfiledComponent\nprofiler = MemoryProfiledComponent()\nstats = profiler.get_memory_stats()\nprint(\"3. Memory Statistics:\")\nprint(f\"   Current: {stats['current_mb']:.2f} MB\")\nprint(f\"   Peak: {stats['peak_mb']:.2f} MB\")\nprint(f\"   Growth: {stats['growth_mb']:.2f} MB\")\nprint()\n\n# 4. Summary\nprint(\"=\" * 60)\nprint(\"Demo Complete!\")\nprint()\nprint(\"Next steps:\")\nprint(\"- View traces in Datadog UI (if configured)\")\nprint(\"- Run load tests to generate profiling data\")\nprint(\"- Explore APM flame graphs and bottleneck analysis\")\nprint(\"=\" * 60)\n\n# Expected: All components work, APM captures profiling data if configured",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}