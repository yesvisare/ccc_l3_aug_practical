{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 9.1: Query Decomposition & Planning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates advanced retrieval techniques for handling complex multi-part queries through decomposition, dependency analysis, and parallel execution.\n",
    "\n",
    "**Problem:** Standard RAG pipelines struggle with complex multi-part queries (15-20% of production traffic). Current simple retrieval approaches yield quality scores of 2.1/5 on complex queries versus 4.2/5 on simple ones.\n",
    "\n",
    "**Solution:** Query decomposition improves complex query accuracy from 2.1/5 to 4.0/5 by:\n",
    "- Breaking queries into atomic sub-queries\n",
    "- Building dependency graphs for optimal execution order\n",
    "- Parallel execution reducing latency by 60% for independent queries\n",
    "- Synthesizing coherent answers from multiple results\n",
    "\n",
    "**Trade-offs:**\n",
    "- Adds 200-500ms overhead (NOT for simple queries)\n",
    "- Higher LLM costs ($0.01-0.02 per complex query)\n",
    "- Complexity in debugging multi-step failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup and imports\nimport sys\nimport os\nimport json\nimport asyncio\nfrom pathlib import Path\n\n# Import from our module\nfrom src.l3_m9_query_decomposition.pipeline import (\n    QueryDecomposer,\n    DependencyGraph,\n    ParallelExecutionEngine,\n    AnswerSynthesizer,\n    QueryDecompositionPipeline,\n    DecompositionError,\n    DependencyError,\n    SynthesisError\n)\nfrom src.l3_m9_query_decomposition.config import Config, get_openai_client\n\n# Load example data\nwith open('../example_data.json', 'r') as f:\n    example_data = json.load(f)\n\nprint(\"‚úì Imports successful\")\nprint(f\"‚úì Example data loaded: {len(example_data['sample_queries'])} queries\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Section 1: Query Decomposition with LLM\n\n**Goal:** Break complex queries into atomic sub-queries using GPT-4 Turbo.\n\n**Key Features:**\n- Temperature = 0.0 for deterministic outputs\n- JSON response format with sub-query IDs and dependencies\n- Validation: Maximum 6 sub-queries\n- Fallback handling for LLM parsing failures\n\n**When this works:**\n- Queries with 2-4 distinct semantic parts\n- Clear independent sub-questions\n\n**When this breaks:**\n- Too granular decomposition (>6 sub-queries)\n- LLM returns invalid JSON\n- Query is actually simple (1 sub-query)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test Query Decomposition\nasync def test_decomposition():\n    if not Config.OPENAI_API_KEY:\n        print(\"‚ö†Ô∏è Skipping API calls (no OPENAI_API_KEY)\")\n        return\n    \n    decomposer = QueryDecomposer(Config.OPENAI_API_KEY)\n    \n    # Test 1: Complex query (should work)\n    complex_query = example_data['sample_queries'][0]['query']\n    print(f\"Query: {complex_query}\\n\")\n    \n    try:\n        result = await decomposer.decompose(complex_query)\n        print(f\"‚úì Decomposed into {len(result.sub_queries)} sub-queries:\")\n        for sq in result.sub_queries[:3]:  # Show max 3\n            print(f\"  - {sq.id}: {sq.query[:60]}...\")\n            if sq.dependencies:\n                print(f\"    Deps: {sq.dependencies}\")\n    except DecompositionError as e:\n        print(f\"‚úó Decomposition failed: {e}\")\n\n# Expected: 3 sub-queries for PostgreSQL vs MySQL comparison\nawait test_decomposition()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: Dependency Graph Construction\n\n**Goal:** Build execution plan using NetworkX DiGraph to represent dependencies.\n\n**Key Features:**\n- Nodes = sub-query IDs\n- Edges = dependency relationships\n- Validates for circular dependencies (raises DependencyError)\n- Generates execution levels for parallel execution\n\n**When this works:**\n- Valid DAG (Directed Acyclic Graph)\n- Clear sequential or parallel patterns\n\n**When this breaks:**\n- Circular dependencies (q1 depends on q2, q2 depends on q1)\n- Missing dependency references\n- Invalid graph structure",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test Dependency Graph\nfrom src.l3_m9_query_decomposition.pipeline import SubQuery\n\n# Example 1: Parallel execution (no dependencies)\nparallel_queries = [\n    SubQuery(id=\"q1\", query=\"PostgreSQL performance?\", dependencies=[]),\n    SubQuery(id=\"q2\", query=\"MySQL performance?\", dependencies=[]),\n    SubQuery(id=\"q3\", query=\"JSON support comparison?\", dependencies=[])\n]\n\ngraph = DependencyGraph(parallel_queries)\nlevels = graph.get_execution_levels()\nprint(f\"‚úì Parallel pattern: {len(levels)} level(s)\")\nprint(f\"  Level 1: {levels[0]}\")\n\n# Example 2: Sequential execution (with dependencies)\nsequential_queries = [\n    SubQuery(id=\"q1\", query=\"AWS Lambda security?\", dependencies=[]),\n    SubQuery(id=\"q2\", query=\"Azure Functions security?\", dependencies=[]),\n    SubQuery(id=\"q3\", query=\"HIPAA recommendation?\", dependencies=[\"q1\", \"q2\"])\n]\n\ngraph2 = DependencyGraph(sequential_queries)\nlevels2 = graph2.get_execution_levels()\nprint(f\"\\n‚úì Sequential pattern: {len(levels2)} level(s)\")\nfor i, level in enumerate(levels2, 1):\n    print(f\"  Level {i}: {level}\")\n\n# Expected: Parallel = 1 level with 3 queries; Sequential = 2 levels",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Parallel Execution Engine\n\n**Goal:** Execute sub-queries concurrently using async/await patterns.\n\n**Key Features:**\n- Semaphore limiting concurrent retrievals (default: 5)\n- Timeout protection per query (default: 30s)\n- Level-based execution respecting dependencies\n- Error isolation (one failure doesn't stop others)\n\n**When this works:**\n- Independent queries in parallel (60% latency reduction)\n- Proper resource limits prevent exhaustion\n\n**When this breaks:**\n- Too many concurrent retrievals (resource exhaustion)\n- Timeout exceeded (>30s per query)\n- Vector database rate limiting",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test Parallel Execution with Mock Retrieval\nimport time\n\nasync def mock_retrieval(query: str) -> str:\n    \"\"\"Mock retrieval simulating 100ms latency.\"\"\"\n    await asyncio.sleep(0.1)\n    return f\"Mock result for: {query[:40]}...\"\n\n# Test parallel execution\nasync def test_parallel_execution():\n    engine = ParallelExecutionEngine(mock_retrieval, max_concurrent=3)\n    \n    # Use parallel queries from previous section\n    start = time.time()\n    results = await engine.execute_level(parallel_queries, {})\n    elapsed = (time.time() - start) * 1000\n    \n    print(f\"‚úì Executed {len(results)} queries in {elapsed:.0f}ms\")\n    print(f\"  (Sequential would be ~{len(results) * 100}ms)\")\n    for qid in list(results.keys())[:2]:  # Show first 2\n        print(f\"  {qid}: {results[qid][:50]}...\")\n\nawait test_parallel_execution()\n\n# Expected: ~100ms for 3 parallel queries vs ~300ms sequential",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 4: Answer Synthesis\n\n**Goal:** Combine multiple sub-query results into a coherent final answer.\n\n**Key Features:**\n- LLM-based synthesis with conflict resolution\n- Context management (max 4K tokens by default)\n- Temperature = 0.3 for balanced creativity/accuracy\n- Handles contradictory information\n\n**When this works:**\n- Sub-results are complementary\n- Total context < 4K tokens\n- Clear synthesis strategy\n\n**When this breaks:**\n- Context overflow (>4K tokens from multiple retrievals)\n- Contradictory sub-answers requiring manual resolution\n- Synthesis cost adds $0.005 per query",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test Answer Synthesis\nasync def test_synthesis():\n    if not Config.OPENAI_API_KEY:\n        print(\"‚ö†Ô∏è Skipping API calls (no OPENAI_API_KEY)\")\n        return\n    \n    synthesizer = AnswerSynthesizer(Config.OPENAI_API_KEY)\n    \n    # Mock sub-results\n    original_query = \"Compare PostgreSQL and MySQL performance and JSON support\"\n    sub_results = {\n        \"q1\": \"PostgreSQL: Excellent ACID compliance, 10K TPS...\",\n        \"q2\": \"MySQL: Fast reads, 15K TPS on simple queries...\",\n        \"q3\": \"PostgreSQL has native JSONB, MySQL added JSON in 5.7...\"\n    }\n    \n    try:\n        answer = await synthesizer.synthesize(\n            original_query,\n            sub_results,\n            parallel_queries\n        )\n        print(f\"‚úì Synthesized answer ({len(answer)} chars):\")\n        print(f\"  {answer[:150]}...\")\n    except SynthesisError as e:\n        print(f\"‚úó Synthesis failed: {e}\")\n\nawait test_synthesis()\n\n# Expected: Coherent comparison integrating all three sub-results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 5: Full Pipeline Integration\n\n**Goal:** End-to-end pipeline with fallback to simple retrieval.\n\n**Key Features:**\n- Automatic complexity detection\n- Fallback on decomposition/execution failures\n- Latency and cost tracking\n- Metadata for debugging\n\n**Decision Logic:**\n- Single sub-query ‚Üí Use simple retrieval\n- Multiple sub-queries ‚Üí Use decomposition\n- Any error + fallback enabled ‚Üí Simple retrieval\n\n**When this works:**\n- Complex queries (2-4 parts) with ‚â•700ms budget\n- Fallback provides resilience\n\n**When this breaks:**\n- Latency budget <700ms (overhead too high)\n- Query volume >100K/day on tight budget",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Test Full Pipeline\nasync def test_full_pipeline():\n    if not Config.OPENAI_API_KEY:\n        print(\"‚ö†Ô∏è Skipping API calls (no OPENAI_API_KEY)\")\n        return\n    \n    pipeline = QueryDecompositionPipeline(\n        Config.OPENAI_API_KEY,\n        mock_retrieval,\n        enable_fallback=True\n    )\n    \n    # Test complex query\n    complex_query = example_data['sample_queries'][0]['query']\n    print(f\"Query: {complex_query[:70]}...\\n\")\n    \n    result = await pipeline.process_query(complex_query)\n    \n    print(f\"‚úì Method: {result['method']}\")\n    print(f\"  Latency: {result['latency_ms']:.0f}ms\")\n    print(f\"  Sub-queries: {result.get('sub_queries', 'N/A')}\")\n    print(f\"  Answer: {result['answer'][:100]}...\")\n\nawait test_full_pipeline()\n\n# Expected: Decomposition method with ~800ms latency",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 6: Common Failure Modes\n\n**Failure scenarios from production:**\n\n1. **Too Granular Decomposition** (10+ sub-queries)\n   - Violates MAX_SUB_QUERIES=6 limit\n   - Fix: Simplify query or increase limit\n\n2. **Circular Dependencies**\n   - q1 depends on q2, q2 depends on q1\n   - Fix: Raises DependencyError, need better decomposition\n\n3. **Parallel Execution Timeouts**\n   - Resource exhaustion from too many concurrent retrievals\n   - Fix: Reduce max_concurrent or increase timeout\n\n4. **Answer Synthesis Conflicts**\n   - Contradictory sub-answers\n   - Fix: Manual intervention or better conflict resolution\n\n5. **Context Overflow**\n   - Multiple retrievals exceeding 4K token limit\n   - Fix: Reduce retrieval size or increase limit",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Demonstrate Failure Modes\nprint(\"Failure Mode 1: Too Granular Decomposition\")\ntoo_complex = example_data['sample_queries'][6]  # Edge case query\nprint(f\"  Query: {too_complex['query'][:60]}...\")\nprint(f\"  Expected: {too_complex['expected_sub_queries']} sub-queries (exceeds limit)\")\n\nprint(\"\\nFailure Mode 2: Circular Dependencies\")\ncircular = [\n    SubQuery(id=\"q1\", query=\"What is X?\", dependencies=[\"q2\"]),\n    SubQuery(id=\"q2\", query=\"What is Y?\", dependencies=[\"q1\"])\n]\ntry:\n    graph_bad = DependencyGraph(circular)\n    print(\"  ‚úó Should have raised DependencyError!\")\nexcept DependencyError as e:\n    print(f\"  ‚úì Caught: {str(e)[:50]}...\")\n\nprint(\"\\nFailure Mode 3: Context Overflow\")\nprint(\"  Scenario: Multiple large retrievals > 4K tokens\")\nprint(\"  Fix: Reduce retrieval size or increase token limit\")\n\nprint(\"\\nFailure Mode 4: Timeout\")\nprint(\"  Scenario: Retrieval takes >30s\")\nprint(\"  Fix: Increase timeout or optimize retrieval\")\n\n# Expected: Circular dependency error caught, others documented",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Section 7: Decision Card - When to Use Query Decomposition\n\n### ‚úÖ Use query decomposition when:\n\n- Query has **2-4 distinct semantic parts**\n- Sub-queries are **largely independent** or have clear dependencies\n- **Latency budget ‚â•700ms** (accounts for 200-500ms overhead)\n- **Accuracy improvement worth cost increase** ($0.01-0.02 per query)\n- Handling **15-20% complex queries** in production traffic\n\n### ‚ùå When NOT to use:\n\n- **Simple Direct Questions** (80%+ of traffic) - Adds unnecessary latency\n- **Real-Time Apps** (<500ms requirement) - Overhead too high\n- **Very High Query Volume** (>100K/day) on limited budget - Costs multiply\n- **Domain-Specific Queries** - May need custom fine-tuning\n\n### üìä Performance Impact:\n\n| Metric | Simple Query | Complex w/o Decomp | Complex w/ Decomp |\n|--------|--------------|-------------------|-------------------|\n| Latency | 200ms | 250ms | 800ms |\n| Quality | 4.2/5 | 2.1/5 | 4.0/5 |\n| Cost | $0.001 | $0.001 | $0.020 |\n\n### üéØ Key Takeaway:\n\nDeploy when **15-20% complex query volume justifies the cost and latency trade-off**. For 80% simple queries, standard retrieval remains optimal.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Decision Helper Function\ndef should_use_decomposition(\n    query_complexity: str,\n    latency_budget_ms: int,\n    query_volume_per_day: int,\n    cost_sensitive: bool\n) -> dict:\n    \"\"\"\n    Decision helper based on query characteristics.\n    \n    Returns recommendation with reasoning.\n    \"\"\"\n    reasons = []\n    score = 0\n    \n    # Complexity check\n    if query_complexity in [\"high\", \"complex\"]:\n        score += 2\n        reasons.append(\"‚úì Complex query benefits from decomposition\")\n    else:\n        reasons.append(\"‚úó Simple query - unnecessary overhead\")\n    \n    # Latency check\n    if latency_budget_ms >= 700:\n        score += 1\n        reasons.append(\"‚úì Latency budget sufficient\")\n    else:\n        reasons.append(\"‚úó Latency budget too tight (<700ms)\")\n    \n    # Volume check\n    if query_volume_per_day < 100000:\n        score += 1\n        reasons.append(\"‚úì Volume manageable for decomposition costs\")\n    else:\n        if cost_sensitive:\n            reasons.append(\"‚úó High volume + cost-sensitive\")\n    \n    recommendation = \"USE\" if score >= 3 else \"SKIP\"\n    \n    return {\n        \"recommendation\": recommendation,\n        \"score\": f\"{score}/4\",\n        \"reasons\": reasons\n    }\n\n# Test decision helper\ntest_cases = [\n    (\"high\", 1000, 50000, False),\n    (\"low\", 300, 10000, True),\n    (\"high\", 500, 150000, True)\n]\n\nfor complexity, latency, volume, cost_sens in test_cases:\n    result = should_use_decomposition(complexity, latency, volume, cost_sens)\n    print(f\"{result['recommendation']} ({result['score']}): {' | '.join(result['reasons'][:2])}\")\n\n# Expected: USE for case 1, SKIP for cases 2 and 3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusion\n\n### What We've Learned:\n\n1. **Query Decomposition** breaks complex multi-part queries into atomic sub-queries\n2. **Dependency Graphs** enable optimal parallel/sequential execution planning\n3. **Parallel Execution** reduces latency by 60% for independent queries\n4. **Answer Synthesis** combines results into coherent responses with conflict resolution\n5. **Trade-offs are real**: +200-500ms latency, 20√ó cost increase, debugging complexity\n\n### Production Checklist:\n\n- ‚úì Fallback to simple retrieval for failures\n- ‚úì Rate limiting on decomposition calls\n- ‚úì Circuit breakers for stuck async operations\n- ‚úì Logging of failed sub-queries for debugging\n- ‚úì Monitoring: success rates, latency, synthesis conflicts\n\n### Alternative Solutions to Consider:\n\n1. **Single-Shot Retrieval with Better Prompting** - Simplest approach\n2. **Query Expansion** (not decomposition) - Middle-ground using semantic variations\n3. **Managed Query Understanding Service** - Zero implementation, vendor-dependent\n4. **Fine-Tuned Decomposition Model** - Advanced for specialized domains\n\n### Next Steps:\n\n- **Module 9.2**: Query Rewriting & Expansion\n- **Module 9.3**: Hybrid Search Techniques\n- **Module 10**: Multi-Modal RAG\n\n---\n\n**Remember:** Only use decomposition when complexity justifies the cost. For 80% of simple queries, standard retrieval is optimal.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}